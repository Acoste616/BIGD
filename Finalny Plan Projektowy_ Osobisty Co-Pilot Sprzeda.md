
Finalny Plan Projektowy: Osobisty Co-Pilot Sprzedaży AI


Część I: Wizja i Strategia Projektu


1. Cel Główny i Filozofia

Cel główny: Stworzenie osobistego, strategicznego co-pilota sprzedaży, który działa jako interaktywne rozszerzenie intuicji sprzedawcy. System ma stać się narzędziem klasy "Ultimate Sales", które w czasie rzeczywistym analizuje informacje o kliencie, dynamicznie ocenia jego intencje i dostarcza precyzyjnych, wysoce spersonalizowanych strategii, pytań i argumentów, aby zmaksymalizować skuteczność sprzedaży.
Filozofia Projektu: System nie jest prostym generatorem odpowiedzi. Jest to partner do strategicznego myślenia, który bierze na siebie ciężar analizy danych i psychologii, pozwalając sprzedawcy skupić się na tym, co najważniejsze – budowaniu relacji i zamykaniu sprzedaży. Dokument ten jest kompletnym i samowystarczalnym blueprintem, zaprojektowanym tak, aby w połączeniu z inspiracjami z bigdecoder.html, stanowić pełną podstawę do budowy nowego, w pełni funkcjonalnego systemu.

2. Kluczowe Wymagania Biznesowe

Głębokie Rozumienie: System musi dogłębnie interpretować nie tylko fakty, ale też emocje, obawy, potrzeby i ukryte motywacje klienta.1
Dynamiczna Adaptacja: System musi na żywo aktualizować swoją analizę i rekomendacje z każdą nową informacją wprowadzoną przez użytkownika, działając jak sufler w teatrze.3
Proaktywne Wsparcie: Zamiast tylko reagować, system ma proaktywnie sugerować najlepsze kolejne ruchy, pytania i sposoby zbijania obiekcji.4
Ocena Potencjału: System musi precyzyznie oceniać ryzyko (np. "fundrive", utrata klienta) i potencjał (gotowość do zakupu, wartość jazdy weekendowej) w czasie rzeczywistym.5
Pamięć Długoterminowa: System musi przechowywać historię interakcji z poszczególnymi klientami, umożliwiając kontynuację rozmowy w przyszłości z pełnym kontekstem.

Część II: Architektura Systemu i Stos Technologiczny


3. Architektura Systemu

System zostanie zbudowany w oparciu o nowoczesną architekturę, zoptymalizowaną pod kątem interakcji z zewnętrznym API i obsługi danych w czasie rzeczywistym.
Frontend (Interfejs Użytkownika): Dynamiczna aplikacja internetowa (Single Page Application) działająca w przeglądarce sprzedawcy.
Backend (Serwer Aplikacji): Centralny mózg operacji, odpowiedzialny za logikę biznesową, komunikację z API Ollama i obsługę połączeń w czasie rzeczywistym.
Zewnętrzne API LLM (Ollama): Usługa dostarczająca model gpt-oss-120b.
Baza Wiedzy (RAG): Wektorowa baza danych (Qdrant), która przechowuje specjalistyczną wiedzę.
Lokalna Baza Danych (Akta Klientów): Relacyjna baza danych (PostgreSQL) do przechowywania historii interakcji, profili klientów i ocen z pętli zwrotnej.
Komunikacja między frontendem a backendem będzie odbywać się za pomocą WebSockets, aby zapewnić natychmiastowe, dwukierunkowe przesyłanie danych.6

4. Stos Technologiczny


Komponent
Technologia
Uzasadnienie i Szczegóły Implementacji
Frontend
React
Idealny dla złożonych, interaktywnych interfejsów. Zostanie zbudowany z podejściem "mobile-first" i z uwzględnieniem standardów dostępności (WCAG 2.1 AA).9
Backend
FastAPI (Python)
Wysoka wydajność i natywna integracja z ekosystemem AI.13
Baza Relacyjna
PostgreSQL + SQLAlchemy
PostgreSQL jako solidna baza danych. SQLAlchemy zostanie użyte jako ORM do zarządzania schematem i interakcjami z bazą w sposób obiektowy i bezpieczny.
Baza Wektorowa RAG
Qdrant
Wydajne i darmowe rozwiązanie open-source, idealne do samodzielnego hostowania.
Wdrożenie
Docker & Docker Compose
Zapewnia spójność i łatwość uruchomienia. Kubernetes jest na tym etapie nadmiarowy.16
CI/CD
GitHub Actions
Zostanie skonfigurowany prosty pipeline CI/CD do automatycznego uruchamiania testów po każdym pushu do repozytorium.


Część III: Rdzeń AI - Model, Wiedza i Logika


5. Model Językowy (LLM) i Baza Wiedzy (RAG)


5.1. Model Językowy (LLM) i API

Projekt będzie wykorzystywał model gpt-oss-120b dostarczany jako usługa przez serwer Ollama, z którym będziemy się komunikować poprzez oficjalną bibliotekę ollama-python. Należy monitorować limity użycia API i zaimplementować w backendzie mechanizm "fallback" na mniejszy model (np. gpt-oss-20b) w przypadku przekroczenia limitów.

5.2. Baza Wiedzy (RAG) - Mózg Specjalisty

Baza Qdrant będzie zawierać ustrukturyzowane dane, które stanowią specjalistyczną wiedzę systemu.
Proces Tworzenia Wektorów (Embeddings): Backend będzie odpowiedzialny za generowanie wektorów. Każdy fragment tekstu dodawany do bazy wiedzy zostanie najpierw przetworzony przez model embeddingowy (np. sentence-transformers/all-MiniLM-L6-v2) w celu stworzenia jego numerycznej reprezentacji, która następnie zostanie zapisana w Qdrant.
Archetypy Klientów: Fundament systemu klasyfikacji.17
Nazwa Archetypu
Kluczowy Opis i Motywacja
Zdobywca Statusu
Postrzega Teslę jako symbol sukcesu i prestiżu.
Strażnik Rodziny
Priorytetem jest bezpieczeństwo i praktyczność.
Pragmatyczny Analityk
Kieruje się danymi, TCO i ROI.
Eko-Entuzjasta
Motywowany wartościami ekologicznymi.
Pionier Technologii
Zafascynowany technologią dla niej samej.
Techniczny Sceptyk
Ma konkretne obawy co do technologii EV.
Lojalista Premium
Doświadczony kierowca tradycyjnych marek premium.
Łowca Okazji
Skupiony na cenie i najlepszej ofercie.
Niezdecydowany Odkrywca
Potrzebuje edukacji i prostych wyjaśnień.
Entuzjasta Osiągów
Kluczowe są przyspieszenie i wrażenia z jazdy.

Moduły Wiedzy Kontekstowej: Dedykowane "paczki wiedzy" aktywowane przez słowa kluczowe (firma, panele, dzieci itp.), zawierające twarde dane i strategie.23

6. Architektura Promptów i Logika Decyzyjna

System opiera się na dynamicznym rozumowaniu, a nie statycznych regułach.
Ciągła Analiza Sygnałów: Każda nowa informacja jest natychmiast analizowana.
Dynamiczne Wzbogacanie Kontekstu (RAG): System identyfikuje słowa kluczowe i automatycznie pobiera odpowiednie moduły wiedzy z Qdrant.
Dynamiczna Reklasyfikacja: AI na bieżąco re-ewaluuje dopasowanie do archetypu.
Ocena Stanu i Potencjału (Podejście Hybrydowe):
Krok 1 (Analiza Jakościowa LLM): LLM ocenia sytuację i generuje opisową analizę.
Krok 2 (Kwantyfikacja w Backendzie): Backend używa prostych, modyfikowalnych reguł do przeliczenia tej analizy na twarde liczby.
Generowanie "Następnego Ruchu": AI otrzymuje kompletny prompt (historia + archetyp + dane z RAG) i generuje 4 najlepsze akcje.

Część IV: Logika Aplikacji i Projekt UI/UX


7. Projekt Interfejsu Użytkownika: Dynamiczny Kokpit Sprzedażowy

Interfejs to dynamiczny, jednoekranowy kokpit, który ewoluuje wraz z rozmową.32
Główne Komponenty:
Interaktywny Terminal Konwersacji: Centralny element do wpisywania obserwacji.
Dynamiczny Panel Akcji ("Następny Ruch"): Bezpośrednio pod polem wprowadzania, system zawsze pokazuje 4 sugerowane akcje. Dodana zostanie opcja "Generuj inne sugestie", która pozwoli na odświeżenie propozycji.
Czat Strategiczny z Doradcą AI: Dedykowane okno do prowadzenia meta-rozmowy z AI.
Pętla Informacji Zwrotnej: Mechanizm oceny sugestii AI (kciuk w górę/dół).
Panel "Akta Klienta": Umożliwia tworzenie nowego profilu klienta lub wczytywanie istniejącego.
Panel Analizy Głównej: Zawsze widoczny, wyświetla kluczowe wskaźniki.
Panel Pełnej Strategii (na żądanie): Dostępny po kliknięciu, zawiera szczegółowe zakładki.

8. Szczegółowy Opis Panelu Pełnej Strategii

Ten panel to Twoja encyklopedia wiedzy o kliencie, zorganizowana w 5 zakładek:
Podsumowanie i Główne Motywacje
Kluczowe Zwroty i Sposób Mówienia
Scenariusz Rozmowy i Następne Kroki
Obsługa Zastrzeżeń
Pytania Kwalifikujące 36

Część V: Uszczelnienie Planu - Rozwiązania dla Zidentyfikowanych Ryzyk


9. Zarządzanie Danymi i Pamięcią

Schemat Bazy Danych (PostgreSQL z SQLAlchemy): Zostanie zaimplementowany klarowny schemat bazy danych, zarządzany przez SQLAlchemy. Przykładowe tabele:
clients: id, name, contact_info, created_at.
sessions: id, client_id, start_time, end_time, summary (text), key_facts (JSONB).
interactions: id, session_id, timestamp, user_input, ai_response_json.
feedback: id, interaction_id, rating (np. 1 dla "up", -1 dla "down").
Zarządzanie Pamięcią Długoterminową (Problem Limitu Tokenów): Zastosujemy strategię hybrydową:
Podsumowanie Konwersacji: Po przekroczeniu określonej liczby tokenów w sesji, backend automatycznie zleci LLM zadanie stworzenia zwięzłego podsumowania dotychczasowej rozmowy.
Ekstrakcja Kluczowych Faktów: Najważniejsze informacje będą zapisywane jako tagi w polu key_facts i zawsze dołączane do promptu.

10. Zarządzanie Aplikacją i Niezawodność

Zarządzanie Aktami Klientów: Aplikacja będzie posiadała dedykowaną sekcję do przeglądania, wyszukiwania i archiwizowania profili klientów.
Zarządzanie Bazą Wiedzy (RAG) z Walidacją: Formularz do dodawania nowej wiedzy zostanie wzbogacony o mechanizm walidacji, który sprawdzi podobieństwo do istniejących wpisów.
Bezpieczeństwo Danych i Kopie Zapasowe: Baza danych będzie szyfrowana, a codzienne, automatyczne backupy zapewnią bezpieczeństwo danych.
Obsługa Błędów i Stany Awaryjne: Interfejs będzie jasno komunikował ewentualne problemy z połączeniem lub API.

Część VI: Plan Wdrożenia i Dalszy Rozwój


11. Fazy Wdrożenia

Konfiguracja Środowisk: Ustawienie środowisk deweloperskich (FastAPI, React).
Wdrożenie Baz Danych: Uruchomienie instancji Qdrant i PostgreSQL za pomocą Dockera.
Budowa Backendu: Implementacja logiki aplikacji, integracja z API i bazami danych.
Budowa Frontendu: Stworzenie dynamicznego kokpitu sprzedażowego.
Zasilenie Bazy Wiedzy: Załadowanie danych do Qdrant.
Konteneryzacja i Wdrożenie: Spakowanie aplikacji do kontenerów Docker.
Testowanie i Optymalizacja: Rygorystyczne testy wydajności i użyteczności.

12. Dalszy Rozwój

Rozbudowa Bazy Wiedzy: Ciągłe dodawanie nowych strategii i danych.
Automatyczne Wzbogacanie Bazy Wiedzy: Stworzenie mechanizmu, w którym najlepsze, najwyżej ocenione interakcje mogą być pół-automatycznie dodawane do bazy wiedzy RAG.
Dostrajanie (Fine-Tuning): W przyszłości, zebrane dane mogą posłużyć do dostrojenia mniejszego, bardziej wyspecjalizowanego modelu.
