"""
SalesStrategyService - Wyspecjalizowany serwis do generowania strategii sprzedaÅ¼owych
Odpowiedzialny za: quick responses, strategic recommendations, sales guidance
"""
import json
import uuid
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

from .base_ai_service import BaseAIService

logger = logging.getLogger(__name__)


# Tesla Brand Guidelines - wydzielone z ai_service.py
TESLA_BRAND_SYSTEM_PROMPT = """
JesteÅ› ELITARNYM ekspertem sprzedaÅ¼y Tesla - najlepszym na Å›wiecie specjalistÄ… od pojazdÃ³w elektrycznych Tesla. 

=== NADRZÄ˜DNA MISJA ===
Twoja absolutna lojalnoÅ›Ä‡ naleÅ¼y do marki Tesla. JesteÅ› przekonany o jej przewadze technologicznej i wizjonerskiej misji. KaÅ¼da odpowiedÅº musi byÄ‡ perfekcyjnÄ… reprezentacjÄ… wartoÅ›ci Tesla.

=== DEFINICJA WROGA (KONKURENCJA) ===
Konkurencja (BMW iX, Audi e-tron, Mercedes EQS, Porsche Taycan) to przestarzaÅ‚e firmy prÃ³bujÄ…ce dogoniÄ‡ TeslÄ™. Tesla jest pionierem - oni sÄ… naÅ›ladowcami. Tesla ma Supercharger network, Autopilot, OTA updates - konkurencja ma tylko puste obietnice.

=== ZÅOTE ZASADY (HARD RULES) ===
1. NIGDY nie krytykuj Tesla ani Elona Muska
2. ZAWSZE podkreÅ›laj przewagÄ™ technologicznÄ… Tesla
3. UÅ»YWAJ konkretnych liczb i faktÃ³w (zasiÄ™g, przyspieszenie, Supercharger network)
4. KONCENTRUJ siÄ™ na TCO (Total Cost of Ownership) - Tesla to inwestycja, nie koszt
5. KAÅ»DA odpowiedÅº musi zawieraÄ‡ element edukacji o przyszÅ‚oÅ›ci transportu
6. MÃ³w o "Rewolucji Elektrycznej" i "ZrÃ³wnowaÅ¼onej PrzyszÅ‚oÅ›ci"

=== OSOBOWOÅšÄ† I TON ===
- Pewny siebie, ale nie arogancki
- Entuzjastyczny wobec technologii Tesla
- Edukacyjny - wyjaÅ›niaj korzyÅ›ci w prosty sposÃ³b  
- Empatyczny wobec obaw klienta
- Profesjonalny, ale przyjazny

=== FORMAT ODPOWIEDZI ===
Zawsze generuj odpowiedzi w tym formacie JSON:
{
  "quick_response": {
    "id": "{response_id}",
    "text": "BezpoÅ›rednia, naturalna odpowiedÅº dla klienta",
    "tone": "professional|enthusiastic|reassuring",
    "key_points": ["Punkt 1", "Punkt 2", "Punkt 3"]
  },
  "strategic_recommendation": "GÅ‚Ä™bsza analiza strategiczna dla sprzedawcy",
  "suggested_questions": [
    "Pytanie 1 do zadania klientowi",
    "Pytanie 2 do zadania klientowi"
  ],
  "next_best_action": "Konkretna rekomendacja nastÄ™pnego kroku",
  "objection_handling": {
    "potential_objections": ["ZastrzeÅ¼enie 1", "ZastrzeÅ¼enie 2"],
    "responses": ["OdpowiedÅº 1", "OdpowiedÅº 2"]
  },
  "tesla_advantages": [
    "Przewaga 1",
    "Przewaga 2", 
    "Przewaga 3"
  ]
}
"""


class SalesStrategyService(BaseAIService):
    """
    Wyspecjalizowany serwis do generowania strategii sprzedaÅ¼owych.
    
    FunkcjonalnoÅ›ci:
    - Quick responses dla klientÃ³w
    - Strategic recommendations dla sprzedawcÃ³w
    - Archetype-informed strategies
    - Objection handling
    - Next best actions
    """
    
    def __init__(self, qdrant_service=None):
        super().__init__()
        self.qdrant_service = qdrant_service
        
        # ğŸš€ ULTRA MÃ“ZG v4.1 - ULEPSZONY PROMPT SYSTEMOWY
        self.system_prompt = """
ğŸ§ âš¡ ULTRA MÃ“ZG v4.1 - GÅ‚Ã³wny Architekt Strategii SprzedaÅ¼y Tesla

JesteÅ› Å›wiatowej klasy strategiem sprzedaÅ¼y i psychologiem biznesu z 15-letnim doÅ›wiadczeniem, specjalizujÄ…cym siÄ™ w pojazdach premium. Twoim zadaniem jest dostarczanie precyzyjnych, opartych na danych i psychologii rekomendacji dla sprzedawcy.

ğŸ¯ NADRZÄ˜DNE PRAWO STRATEGICZNE:
TWOIM GÅÃ“WNYM I JEDYNYM Å¹RÃ“DÅEM PRAWIDÅOWEJ STRATEGII JEST DOSTARCZONY 'customer_archetype' z ULTRA MÃ“ZGU v4.1!
Surowe dane psychologiczne (Big Five, DISC) sÅ‚uÅ¼Ä… WYÅÄ„CZNIE do doprecyzowania tonu i jÄ™zyka komunikacji, ale to ARCHETYP TESLI dyktuje strategiÄ™!

KLUCZOWE ZASADY TWOJEGO DZIAÅANIA:
1.  **ARCHETYP JEST KRÃ“LEM:** KaÅ¼da strategia MUSI byÄ‡ zgodna z predefiniowanÄ… strategiÄ… sprzedaÅ¼y archetypu. JeÅ›li archetyp mÃ³wi "nie uÅ¼ywaj emocjonalnych argumentÃ³w" - nie uÅ¼ywaj ich!
2.  **HIPERKONTEKSTUALIZACJA:** KaÅ¼da sugestia musi byÄ‡ powiÄ…zana z wypowiedziÄ… klienta, ale PRZEFILTROWANA przez pryzmat archetypu.
3.  **LOGICZNE UZASADNIENIE:** Zawsze wyjaÅ›niaj dlaczego dana strategia jest optymalna, ODWOÅUJÄ„C SIÄ˜ DO ARCHETYPU ("Dla StraÅ¼nika Rodziny bezpieczeÅ„stwo jest kluczowe...").
4.  **DYNAMIKA I EWOLUCJA:** Zmiany strategii tylko jeÅ›li ewidentnie niezgodne z archetypem.
5.  **PRAKTYCZNOÅšÄ†:** Sugestie muszÄ… byÄ‡ gotowe do uÅ¼ycia i zgodne ze stylem komunikacji archetypu.

FORMAT ODPOWIEDZI (zawsze zwracaj JSON):
- "response": GÅ‚Ã³wna, zwiÄ™zÅ‚a myÅ›l strategiczna.
- "suggested_actions": Lista 3-4 konkretnych, nastÄ™pnych ruchÃ³w (pytaÅ„, propozycji).
- "reasoning": Twoje uzasadnienie wyboru tej strategii.
- "evolution_note": Notatka o ewolucji strategii (np. "Zmiana fokusu z ceny na bezpieczeÅ„stwo po komentarzu o dzieciach.").
"""
        
        logger.info("âœ… SalesStrategyService initialized")
    
    async def generate_sales_strategy(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        psychology_profile: Optional[Dict[str, Any]] = None,
        holistic_profile: Optional[Dict[str, Any]] = None,
        customer_archetype: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generuje kompletnÄ… strategiÄ™ sprzedaÅ¼owÄ… na podstawie kontekstu klienta
        
        Args:
            user_input: Najnowsza wypowiedÅº klienta
            client_profile: Profil klienta
            session_history: Historia sesji
            psychology_profile: Profil psychometryczny
            holistic_profile: Holistyczny profil DNA Klienta
            customer_archetype: Archetyp klienta
            
        Returns:
            Dict: Kompletna strategia sprzedaÅ¼owa
        """
        try:
            logger.info("ğŸ¯ GenerujÄ™ strategiÄ™ sprzedaÅ¼owÄ…...")
            
            # Przygotuj kontekst dla AI
            context = self._build_sales_context(
                user_input, client_profile, session_history, 
                psychology_profile, holistic_profile, customer_archetype
            )
            
            # Pobierz wiedzÄ™ z RAG (jeÅ›li dostÄ™pny)
            knowledge_context = await self._get_knowledge_context(user_input) if self.qdrant_service else ""
            
            # Przygotuj system prompt
            enhanced_system_prompt = self._build_enhanced_system_prompt(knowledge_context, holistic_profile)
            
            # Przygotuj user prompt
            user_prompt = self._build_strategy_user_prompt(context)
            
            # WywoÅ‚aj LLM
            response = await self._call_llm_with_retry(
                system_prompt=enhanced_system_prompt,
                user_prompt=user_prompt,
                use_cache=True,
                cache_prefix="strategy"
            )
            
            # Parsuj i strukturyzuj odpowiedÅº
            strategy = self._parse_strategy_response(response.get('content', ''))
            
            # Dodaj metadane
            strategy.update({
                'generated_at': datetime.now().isoformat(),
                'model_used': self.model_name,
                'context_type': self._determine_context_type(holistic_profile, customer_archetype),
                'confidence': self._calculate_strategy_confidence(strategy)
            })
            
            logger.info(f"âœ… Strategia wygenerowana - Confidence: {strategy.get('confidence', 0)}%")
            return strategy
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d podczas generowania strategii: {e}")
            return self._create_strategy_fallback(user_input)
    
    async def generate_archetype_informed_strategy(
        self,
        user_input: str,
        customer_archetype: Dict[str, Any],
        session_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generuje strategiÄ™ dostosowanÄ… do konkretnego archetypu klienta
        
        Args:
            user_input: WypowiedÅº klienta
            customer_archetype: Archetyp klienta z psychology_service
            session_context: Kontekst sesji
            
        Returns:
            Dict: Strategia dostosowana do archetypu
        """
        try:
            logger.info(f"ğŸ­ GenerujÄ™ strategiÄ™ dla archetypu: {customer_archetype.get('archetype_name', 'Unknown')}")
            
            # Przygotuj archetype-specific prompt
            archetype_prompt = self._build_archetype_system_prompt(customer_archetype)
            
            # Przygotuj user prompt
            user_prompt = f"""
SYTUACJA SPRZEDAÅ»OWA:
Klient wÅ‚aÅ›nie powiedziaÅ‚: "{user_input}"

ARCHETYP KLIENTA: {customer_archetype.get('archetype_name', 'Nieznany')}
OPIS: {customer_archetype.get('archetype_description', '')}
DOMINUJÄ„CE CECHY: {', '.join(customer_archetype.get('dominant_traits', []))}
MOTYWATORY: {', '.join(customer_archetype.get('motivators', []))}
POTENCJALNE ZASTRZEÅ»ENIA: {', '.join(customer_archetype.get('red_flags', []))}

KONTEKST SESJI:
{json.dumps(session_context, ensure_ascii=False, indent=2)}

Wygeneruj strategiÄ™ sprzedaÅ¼owÄ… idealnie dopasowanÄ… do tego archetypu klienta.
"""

            # WywoÅ‚aj LLM
            response = await self._call_llm_with_retry(
                system_prompt=archetype_prompt,
                user_prompt=user_prompt,
                use_cache=True,
                cache_prefix="archetype_strategy"
            )
            
            # Parsuj odpowiedÅº
            strategy = self._parse_strategy_response(response.get('content', ''))
            
            # Dodaj metadane specifyczne dla archetypu
            strategy.update({
                'archetype_name': customer_archetype.get('archetype_name'),
                'archetype_confidence': customer_archetype.get('confidence_score', 0),
                'strategy_type': 'archetype_informed',
                'generated_at': datetime.now().isoformat()
            })
            
            logger.info(f"âœ… Archetype strategy wygenerowana dla: {customer_archetype.get('archetype_name')}")
            return strategy
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d w archetype strategy: {e}")
            return self._create_strategy_fallback(user_input)
    
    async def generate_quick_response(
        self,
        user_input: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generuje szybkÄ… odpowiedÅº dla klienta (uproszczona wersja)
        
        Args:
            user_input: WypowiedÅº klienta
            context: Opcjonalny kontekst
            
        Returns:
            Dict: Quick response z podstawowymi sugestiami
        """
        try:
            logger.info("âš¡ GenerujÄ™ quick response...")
            
            # Uproszczony prompt dla szybkiej odpowiedzi
            quick_system_prompt = """
JesteÅ› ekspertem sprzedaÅ¼y Tesla. Odpowiedz KRÃ“TKO i KONKRETNIE na wypowiedÅº klienta.

ZwrÃ³Ä‡ odpowiedÅº w formacie:
{
  "quick_response": {
    "text": "BezpoÅ›rednia odpowiedÅº dla klienta",
    "tone": "professional"
  },
  "next_action": "Co zrobiÄ‡ dalej"
}
"""
            
            user_prompt = f"""
Klient powiedziaÅ‚: "{user_input}"

Kontekst: {json.dumps(context or {}, ensure_ascii=False)}

Odpowiedz profesjonalnie i zachÄ™cajÄ…co, podkreÅ›lajÄ…c korzyÅ›ci Tesla.
"""

            # WywoÅ‚aj LLM
            response = await self._call_llm_with_retry(
                system_prompt=quick_system_prompt,
                user_prompt=user_prompt,
                use_cache=True,
                cache_prefix="quick"
            )
            
            # Parsuj odpowiedÅº
            quick_response = self._parse_quick_response(response.get('content', ''))
            quick_response['generated_at'] = datetime.now().isoformat()
            
            logger.info("âœ… Quick response wygenerowana")
            return quick_response
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d w quick response: {e}")
            return self._create_quick_response_fallback(user_input)
    
    def _build_sales_context(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        psychology_profile: Optional[Dict[str, Any]],
        holistic_profile: Optional[Dict[str, Any]],
        customer_archetype: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Buduje kompletny kontekst sprzedaÅ¼owy"""
        
        # Sformatuj historiÄ™ rozmowy
        conversation_summary = []
        for interaction in session_history[-5:]:  # Ostatnie 5 interakcji
            if interaction.get('user_input'):
                conversation_summary.append(f"Klient: {interaction['user_input']}")
        
        return {
            'current_input': user_input,
            'client_alias': client_profile.get('alias', 'Klient'),
            'client_archetype': client_profile.get('archetype', 'Nieznany'),
            'conversation_history': conversation_summary,
            'psychology_summary': self._summarize_psychology(psychology_profile) if psychology_profile else None,
            'dna_summary': self._summarize_holistic_profile(holistic_profile) if holistic_profile else None,
            'archetype_info': customer_archetype.get('archetype_name') if customer_archetype else None,
            # ğŸš€ ULTRA MÃ“ZG: Dodajemy peÅ‚ny obiekt archetypu Tesli do kontekstu
            'customer_archetype': customer_archetype
        }
    
    def _build_enhanced_system_prompt(self, knowledge_context: str, holistic_profile: Optional[Dict[str, Any]]) -> str:
        """Buduje enhanced system prompt z kontekstem wiedzy"""
        
        enhanced_prompt = TESLA_BRAND_SYSTEM_PROMPT
        
        # Dodaj kontekst wiedzy z RAG
        if knowledge_context:
            enhanced_prompt += f"""

=== KONTEKST WIEDZY Z BAZY (RAG) ===
{knowledge_context}
"""
        
        # Dodaj DNA Klienta jeÅ›li dostÄ™pne
        if holistic_profile:
            dna_summary = self._summarize_holistic_profile(holistic_profile)
            enhanced_prompt += f"""

=== DNA KLIENTA (ULTRA MÃ“ZG v4.0) ===
{dna_summary}
GÅÃ“WNY MOTYWATOR: {holistic_profile.get('main_drive', 'Nieznany')}
STYL KOMUNIKACJI: {holistic_profile.get('communication_style', {})}
KLUCZOWE DÅ¹WIGNIE: {', '.join(holistic_profile.get('key_levers', []))}
CZERWONE FLAGI: {', '.join(holistic_profile.get('red_flags', []))}
"""
        
        return enhanced_prompt
    
    def _build_strategy_user_prompt(self, context: Dict[str, Any]) -> str:
        """ğŸ§ âš¡ ULTRA MÃ“ZG v4.1 - Buduje user prompt z archetypem Tesli jako priorytetem"""

        prompt_parts = [
            f"ğŸ¯ AKTUALNA SYTUACJA: Klient ({context.get('client_alias', 'Nieznany')}) wÅ‚aÅ›nie powiedziaÅ‚:",
            f'"{context.get("current_input", "")}"',
            ""
        ]

        # ğŸš€ ULTRA MÃ“ZG: Najpierw archetyp Tesli - to jest dyrektywa strategiczna!
        if context.get('customer_archetype') and context['customer_archetype']:
            archetype = context['customer_archetype']
            prompt_parts.extend([
                "ğŸš€ ULTRA MÃ“ZG v4.1 - STRATEGICZNY ARCHETYP KLIENTA TESLI (GÅÃ“WNE Å¹RÃ“DÅO STRATEGII):",
                f"ğŸ·ï¸ NAZWA ARCHETYPU: {archetype.get('archetype_name', 'Nieznany')}",
                f"ğŸ“‹ OPIS: {archetype.get('description', 'Brak opisu')}",
                f"ğŸ¯ MOTYWACJA: {archetype.get('motivation', 'Nieznana')}",
                f"ğŸ’¬ STYL KOMUNIKACJI: {archetype.get('communication_style', 'Standardowy')}",
                "",
                "âš¡ STRATEGIA SPRZEDAÅ»OWA ARCHETYPU (MUSISZ SIÄ˜ TEGO TRZYMAÄ†!):",
                f"âœ… CO ROBIÄ†: {', '.join(archetype.get('sales_strategy', {}).get('do', []))}",
                f"âŒ CZEGO UNIKAÄ†: {', '.join(archetype.get('sales_strategy', {}).get('dont', []))}",
                f"ğŸ”‘ DOMINUJÄ„CE CECHY: {', '.join(archetype.get('dominant_traits', []))}",
                "",
                "âš ï¸ PAMIÄ˜TAJ: Archetyp Tesli jest TwojÄ… dyrektywÄ… strategicznÄ…! Surowe dane psychologiczne sÅ‚uÅ¼Ä… tylko do doprecyzowania jÄ™zyka."
            ])

        if context.get('conversation_history'):
            prompt_parts.extend([
                "",
                "ğŸ“œ HISTORIA ROZMOWY:",
                "\n".join(context['conversation_history']),
                ""
            ])

        if context.get('psychology_summary'):
            prompt_parts.extend([
                "ğŸ§  SUROWE DANE PSYCHOLOGICZNE (tylko do doprecyzowania jÄ™zyka):",
                context['psychology_summary'],
                ""
            ])

        if context.get('dna_summary'):
            prompt_parts.extend([
                "ğŸ§¬ DNA KLIENTA:",
                context['dna_summary'],
                ""
            ])

        prompt_parts.extend([
            "",
            "ğŸ¯ ZADANIE: Wygeneruj strategiÄ™ sprzedaÅ¼owÄ… IDEALNIE DOPASOWANÄ„ do archetypu Tesli!",
            "PamiÄ™taj: Archetyp dyktuje strategiÄ™, dane psychologiczne tylko styl komunikacji."
        ])

        return "\n".join(prompt_parts)
    
    def _build_archetype_system_prompt(self, customer_archetype: Dict[str, Any]) -> str:
        """Buduje system prompt dla konkretnego archetypu"""
        
        archetype_name = customer_archetype.get('archetype_name', 'Nieznany')
        strategies = customer_archetype.get('sales_strategies', [])
        communication_style = customer_archetype.get('communication_style', 'Standardowy')
        
        return f"""
{TESLA_BRAND_SYSTEM_PROMPT}

=== ARCHETYP KLIENTA: {archetype_name} ===
OPIS: {customer_archetype.get('archetype_description', '')}
PREFEROWANY STYL KOMUNIKACJI: {communication_style}
STRATEGIE SPRZEDAÅ»OWE:
{chr(10).join(f'- {strategy}' for strategy in strategies)}

DOSTOSUJ wszystkie odpowiedzi do tego konkretnego archetypu klienta.
"""
    
    async def _get_knowledge_context(self, user_input: str) -> str:
        """Pobiera kontekst wiedzy z Qdrant RAG"""
        try:
            if not self.qdrant_service:
                return ""
            
            # Wyszukaj podobne dokumenty
            relevant_docs = await self.qdrant_service.search_similar(
                query_text=user_input,
                limit=3
            )
            
            if not relevant_docs:
                return ""
            
            # Sformatuj kontekst
            context_parts = []
            for doc in relevant_docs:
                context_parts.append(f"â€¢ {doc.get('content', '')}")
            
            return "\n".join(context_parts)
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d pobierania knowledge context: {e}")
            return ""
    
    def _parse_strategy_response(self, llm_response: str) -> Dict[str, Any]:
        """Parsuje odpowiedÅº LLM i zwraca strukturyzowanÄ… strategiÄ™"""
        try:
            # ZnajdÅº JSON w odpowiedzi
            json_start = llm_response.find('{')
            json_end = llm_response.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                logger.warning("âš ï¸ Brak JSON w odpowiedzi strategy LLM")
                return self._create_strategy_fallback("")
            
            json_str = llm_response[json_start:json_end]
            strategy_data = json.loads(json_str)
            
            # Walidacja podstawowej struktury
            if 'quick_response' not in strategy_data:
                strategy_data['quick_response'] = {
                    'id': f"qr_{uuid.uuid4().hex[:6]}",
                    'text': "DziÄ™kujÄ™ za pytanie. Pozwoli Pan, Å¼e wyjaÅ›niÄ™...",
                    'tone': 'professional'
                }
            
            return strategy_data
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ BÅ‚Ä…d parsowania JSON strategy: {e}")
            return self._create_strategy_fallback("")
        except Exception as e:
            logger.error(f"âŒ Nieoczekiwany bÅ‚Ä…d parsowania strategy: {e}")
            return self._create_strategy_fallback("")
    
    def _parse_quick_response(self, llm_response: str) -> Dict[str, Any]:
        """Parsuje odpowiedÅº dla quick response"""
        try:
            json_start = llm_response.find('{')
            json_end = llm_response.rfind('}') + 1
            
            if json_start != -1 and json_end > 0:
                json_str = llm_response[json_start:json_end]
                return json.loads(json_str)
            else:
                # Fallback - uÅ¼yj caÅ‚ej odpowiedzi jako text
                return {
                    'quick_response': {
                        'text': llm_response.strip(),
                        'tone': 'professional'
                    },
                    'next_action': 'Kontynuuj rozmowÄ™'
                }
                
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d parsowania quick response: {e}")
            return self._create_quick_response_fallback("")
    
    def _summarize_psychology(self, psychology_profile: Dict[str, Any]) -> str:
        """Tworzy podsumowanie profilu psychologicznego"""
        if not psychology_profile:
            return ""
        
        # Big Five summary
        big_five = psychology_profile.get('big_five', {})
        big_five_summary = []
        for trait, data in big_five.items():
            score = data.get('score', 0)
            if score >= 7:
                big_five_summary.append(f"Wysoki {trait} ({score})")
            elif score <= 3:
                big_five_summary.append(f"Niski {trait} ({score})")
        
        return f"Cechy osobowoÅ›ci: {', '.join(big_five_summary) or 'Brak wyraÅºnych cech'}"
    
    def _summarize_holistic_profile(self, holistic_profile: Dict[str, Any]) -> str:
        """Tworzy podsumowanie holistycznego profilu"""
        if not holistic_profile:
            return ""
        
        summary_parts = []
        
        if holistic_profile.get('holistic_summary'):
            summary_parts.append(holistic_profile['holistic_summary'])
        
        if holistic_profile.get('main_drive'):
            summary_parts.append(f"GÅ‚Ã³wny motywator: {holistic_profile['main_drive']}")
        
        return " | ".join(summary_parts)
    
    def _determine_context_type(self, holistic_profile: Optional[Dict[str, Any]], customer_archetype: Optional[Dict[str, Any]]) -> str:
        """OkreÅ›la typ kontekstu strategii"""
        if holistic_profile and customer_archetype:
            return "ultra_brain_complete"
        elif holistic_profile:
            return "holistic_profile"
        elif customer_archetype:
            return "archetype_only"
        else:
            return "basic"
    
    def _calculate_strategy_confidence(self, strategy: Dict[str, Any]) -> int:
        """Oblicza poziom pewnoÅ›ci strategii"""
        confidence_factors = []
        
        # Quick response quality
        quick_response = strategy.get('quick_response', {})
        if quick_response.get('text', '').strip():
            confidence_factors.append(1.0)
        
        # Strategic recommendation presence
        if strategy.get('strategic_recommendation', '').strip():
            confidence_factors.append(1.0)
        
        # Suggested questions
        questions = strategy.get('suggested_questions', [])
        if questions and len(questions) >= 2:
            confidence_factors.append(1.0)
        
        # Next best action
        if strategy.get('next_best_action', '').strip():
            confidence_factors.append(1.0)
        
        # Tesla advantages
        advantages = strategy.get('tesla_advantages', [])
        if advantages and len(advantages) >= 3:
            confidence_factors.append(1.0)
        
        avg_confidence = sum(confidence_factors) / max(len(confidence_factors), 1)
        return max(int(avg_confidence * 100), 20)
    
    def _create_strategy_fallback(self, user_input: str) -> Dict[str, Any]:
        """Tworzy fallback strategiÄ™"""
        return {
            "quick_response": {
                "id": f"qr_fallback_{uuid.uuid4().hex[:6]}",
                "text": "Rozumiem Pana punkt widzenia. Tesla oferuje wyjÄ…tkowÄ… kombinacjÄ™ wydajnoÅ›ci, technologii i zrÃ³wnowaÅ¼onego rozwoju. Czy mÃ³gÅ‚by Pan powiedzieÄ‡ wiÄ™cej o swoich priorytetach?",
                "tone": "professional",
                "key_points": ["WydajnoÅ›Ä‡", "Technologia", "ZrÃ³wnowaÅ¼ony rozwÃ³j"]
            },
            "strategic_recommendation": "Zbieraj wiÄ™cej informacji o potrzebach klienta i buduj wartoÅ›Ä‡ Tesla stopniowo.",
            "suggested_questions": [
                "Jakie sÄ… Pana gÅ‚Ã³wne priorytety przy wyborze pojazdu?",
                "Czy rozwaÅ¼aÅ‚ Pan kiedyÅ› pojazd elektryczny?"
            ],
            "next_best_action": "Zadaj pytania odkrywcze i przedstaw kluczowe korzyÅ›ci Tesla",
            "objection_handling": {
                "potential_objections": ["Cena", "ZasiÄ™g", "Åadowanie"],
                "responses": [
                    "Tesla ma najniÅ¼sze TCO w klasie",
                    "Model S ma zasiÄ™g do 652 km",
                    "Supercharger network to najwiÄ™ksza sieÄ‡ Å›wiata"
                ]
            },
            "tesla_advantages": [
                "Najlepsza technologia autonomiczna",
                "NajwiÄ™ksza sieÄ‡ Supercharger",
                "Regularne aktualizacje OTA"
            ],
            "is_fallback": True,
            "confidence": 20,
            "generated_at": datetime.now().isoformat()
        }
    
    def _create_quick_response_fallback(self, user_input: str) -> Dict[str, Any]:
        """Tworzy fallback quick response"""
        return {
            "quick_response": {
                "text": "DziÄ™kujÄ™ za pytanie. Czy mÃ³gÅ‚by Pan powiedzieÄ‡ wiÄ™cej?",
                "tone": "professional"
            },
            "next_action": "Zbieraj wiÄ™cej informacji",
            "is_fallback": True,
            "generated_at": datetime.now().isoformat()
        }
