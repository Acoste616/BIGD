"""
AI Service - Integracja z modelem jÄ™zykowym (LLM) poprzez Ollama
"""
import json
import asyncio
import uuid
from typing import Dict, List, Any, Optional, cast
from datetime import datetime
import logging

import ollama
from app.core.config import settings

# --- POCZÄ„TEK ZMIAN ---

# Dynamiczne tworzenie nagÅ‚Ã³wkÃ³w do autoryzacji w Ollama Turbo
headers = {}
if settings.OLLAMA_API_KEY:
    headers['Authorization'] = f'Bearer {settings.OLLAMA_API_KEY}'

# Inicjalizacja klienta z hostem i nagÅ‚Ã³wkami
client = ollama.Client(
    host=settings.OLLAMA_API_URL,
    headers=headers
)

# --- KONIEC ZMIAN ---

from ollama import Client
from pydantic import ValidationError

from app.schemas.interaction import InteractionResponse
from app.models.domain import Client as DomainClient, Session, Interaction
from .qdrant_service import QdrantService

logger = logging.getLogger(__name__)


# Prompt psychometryczny dla ModuÅ‚u 2: Zintegrowana Analiza Psychometryczna
PSYCHOMETRIC_SYSTEM_PROMPT = """
JesteÅ› ekspertem w dziedzinie psychologii sprzedaÅ¼y i lingwistyki. Twoim zadaniem jest przeanalizowaÄ‡ poniÅ¼szÄ… transkrypcjÄ™ rozmowy sprzedaÅ¼owej i stworzyÄ‡ szczegÃ³Å‚owy profil psychometryczny klienta. Wynik przedstaw WYÅÄ„CZNIE jako JSON zgodny z podanÄ… strukturÄ….

KROKI ANALIZY:

1. **Analiza Big Five:** OceÅ„ klienta w 5 wymiarach osobowoÅ›ci (0-10). Dla kaÅ¼dej cechy podaj UZASADNIENIE (rationale) z cytatami z rozmowy oraz STRATEGIÄ˜ sprzedaÅ¼owÄ… dostosowanÄ… do tej cechy.

2. **Analiza DISC:** OceÅ„ dominujÄ…cy styl zachowania klienta (0-10) w 4 wymiarach. Dla kaÅ¼dej cechy podaj UZASADNIENIE z przykÅ‚adami oraz STRATEGIÄ˜ sprzedaÅ¼owÄ….

3. **Analiza WartoÅ›ci Schwartza:** Zidentyfikuj, ktÃ³re z kluczowych wartoÅ›ci (BezpieczeÅ„stwo, WÅ‚adza, OsiÄ…gniÄ™cia, Hedonizm, Stymulacja, Samostanowienie, Uniwersalizm, Å»yczliwoÅ›Ä‡, Tradycja, Przystosowanie) sÄ… obecne w wypowiedziach klienta. Dla kaÅ¼dej podaj UZASADNIENIE i STRATEGIÄ˜.

ENHANCED GUIDELINES - Precyzyjna Analiza:

BIG FIVE - WskazÃ³wki Specyficzne:
- Openness (0-10): Czy klient pyta o nowe technologie, innowacje, funkcje przyszÅ‚oÅ›ci?
- Conscientiousness (0-10): Czy wymaga szczegÃ³Å‚Ã³w, danych, planuje dÅ‚ugoterminowo?
- Extraversion (0-10): Czy mÃ³wi o innych ludziach, statusie, wraÅ¼eniu na otoczenie?
- Agreeableness (0-10): Czy unika konfrontacji, szuka konsensusu, jest uprzejmy?
- Neuroticism (0-10): Czy wyraÅ¼a obawy, stres, niepewnoÅ›Ä‡, potrzebÄ™ bezpieczeÅ„stwa?

DISC - WskazÃ³wki Behawioralne:
- Dominance (0-10): Czy jest bezpoÅ›redni, decyzyjny, chce kontrolowaÄ‡ proces?
- Influence (0-10): Czy jest towarzyski, perswazyjny, opowiada historie?
- Steadiness (0-10): Czy jest cierpliwy, lojalny, szuka stabilnoÅ›ci?
- Compliance (0-10): Czy jest analityczny, systematyczny, potrzebuje dowodÃ³w?

SCHWARTZ VALUES - Kluczowe Motywatory:
- BezpieczeÅ„stwo: Gwarancje, koszty, niezawodnoÅ›Ä‡
- WÅ‚adza: Status, prestiÅ¼, kontrola, wpÅ‚yw na innych
- OsiÄ…gniÄ™cia: Sukces, kompetencje, wyniki, efektywnoÅ›Ä‡
- Hedonizm: PrzyjemnoÅ›Ä‡, komfort, luksus
- Stymulacja: NowoÅ›Ä‡, wyzwania, ekscytacja
- Samostanowienie: NiezaleÅ¼noÅ›Ä‡, autonomia, wÅ‚asne decyzje
- Uniwersalizm: Ekologia, dobro ogÃ³Å‚u, sprawiedliwoÅ›Ä‡
- Å»yczliwoÅ›Ä‡: Troska o innych, relacje, wspÃ³Å‚praca
- Tradycja: Szacunek dla kultury, stabilne wartoÅ›ci
- Przystosowanie: Dopasowanie do norm, uprzejmoÅ›Ä‡

STRUKTURA WYJÅšCIOWA - zwrÃ³Ä‡ WYÅÄ„CZNIE ten JSON:
{
  "big_five": {
    "openness": { "score": 7, "rationale": "Klient wypowiedziaÅ‚: '[cytat z rozmowy]', co wskazuje na...", "strategy": "Skoncentruj siÄ™ na innowacyjnych cechach Tesla..." },
    "conscientiousness": { "score": 8, "rationale": "Z wypowiedzi '[cytat]' wynika...", "strategy": "Przedstaw szczegÃ³Å‚owe dane o ROI i TCO..." },
    "extraversion": { "score": 6, "rationale": "...", "strategy": "..." },
    "agreeableness": { "score": 5, "rationale": "...", "strategy": "..." },
    "neuroticism": { "score": 4, "rationale": "...", "strategy": "..." }
  },
  "disc": {
    "dominance": { "score": 6, "rationale": "Klient wykazuje cechy dominacji przez...", "strategy": "BÄ…dÅº bezpoÅ›redni, prezentuj fakty..." },
    "influence": { "score": 4, "rationale": "...", "strategy": "..." },
    "steadiness": { "score": 7, "rationale": "...", "strategy": "..." },
    "compliance": { "score": 8, "rationale": "...", "strategy": "..." }
  },
  "schwartz_values": [
    { "value_name": "BezpieczeÅ„stwo", "is_present": true, "rationale": "Klient wyraziÅ‚ obawy o...", "strategy": "PodkreÅ›l najwyÅ¼sze oceny bezpieczeÅ„stwa Tesla..." },
    { "value_name": "OsiÄ…gniÄ™cia", "is_present": false, "rationale": "Brak oznak zorientowania na sukces...", "strategy": "..." }
  ]
}

KLUCZOWE WYMAGANIA:
- KaÅ¼de uzasadnienie MUSI zawieraÄ‡ konkretne cytaty z rozmowy
- Strategie muszÄ… byÄ‡ praktyczne i gotowe do uÅ¼ycia przez sprzedawcÄ™ Tesla
- Oceny muszÄ… byÄ‡ realistyczne i oparte na faktycznych dowodach z tekstu
- JSON musi byÄ‡ poprawnie sformatowany (bez komentarzy)

JEÅšLI BRAK WYSTARCZAJÄ„CYCH DANYCH:
JeÅ›li rozmowa jest zbyt krÃ³tka lub nie zawiera wystarczajÄ…cych informacji do precyzyjnej analizy psychometrycznej, 
zamiast JSON zwrÃ³Ä‡:

{
  "insufficient_data": true,
  "probing_questions": [
    "Konkretne pytanie pomagajÄ…ce okreÅ›liÄ‡ Big Five",
    "Pytanie o styl komunikacji (DISC)",
    "Pytanie o motywacje i wartoÅ›ci (Schwartz)"
  ],
  "analysis_confidence": "low",
  "suggestions": "Co sprzedawca powinien sprawdziÄ‡ aby lepiej zrozumieÄ‡ psychologiÄ™ klienta"
}
"""

# Enhanced prompt dla Dwuetapowej Analizy Psychometrycznej
DUAL_STAGE_PSYCHOMETRIC_PROMPT = """
JesteÅ› ekspertem psychologii sprzedaÅ¼y prowadzÄ…cym DWUETAPOWÄ„ ANALIZÄ˜ klienta.

ETAP 1 - WSTÄ˜PNA ANALIZA:
1. Przeanalizuj dostÄ™pny tekst pod kÄ…tem Big Five, DISC i Schwartz
2. Dla kaÅ¼dego wymiaru oblicz wstÄ™pnÄ… ocenÄ™ i PEWNOÅšÄ† tej oceny (0-100%)
3. Oblicz OGÃ“LNÄ„ PEWNOÅšÄ† caÅ‚ej analizy jako Å›redniÄ… waÅ¼onÄ…

ETAP 2 - SAMOOCENA AI:
Zadaj sobie pytanie: "Czy na podstawie dostarczonych informacji mÃ³j poziom pewnoÅ›ci 
co do okreÅ›lonego profilu psychometrycznego jest wystarczajÄ…co wysoki (â‰¥75%)?"

JEÅšLI PEWNOÅšÄ† â‰¥ 75%:
ZwrÃ³Ä‡ peÅ‚nÄ… analizÄ™ psychometrycznÄ… bez dodatkowych pytaÅ„.

JEÅšLI PEWNOÅšÄ† < 75%:
Zidentyfikuj KONKRETNIE jakich informacji brakuje i wygeneruj 2-3 pytania A/B dla sprzedawcy.

STRUKTURA ODPOWIEDZI:
{
  "confidence_score": 85,
  "needs_clarification": false,
  "analysis_stage": "confirmed",
  "big_five": { ... },
  "disc": { ... },
  "schwartz_values": [ ... ],
  "clarifying_questions": [
    {
      "id": "q1_decision_style",
      "question": "Jak klient podejmuje decyzje?",
      "option_a": "Szybko, intuicyjnie", 
      "option_b": "Wolno, po szczegÃ³Å‚owej analizie",
      "psychological_target": "Conscientiousness vs Openness"
    }
  ]
}

KLUCZOWE: Pytania sÄ… dla SPRZEDAWCY o jego OBSERWACJE, nie do zadania klientowi!
"""

# Prompt dla Enhanced Response Generation z profilem psychometrycznym
PSYCHOLOGICALLY_INFORMED_RESPONSE_PROMPT = """
JesteÅ› ekspertem sprzedaÅ¼y Tesla generujÄ…cym PSYCHOLOGICZNIE DOSTOSOWANÄ„ odpowiedÅº.

Otrzymujesz POTWIERDZONY profil psychometryczny klienta i musisz wygenerowaÄ‡ 
sugerowanÄ… odpowiedÅº ktÃ³ra jest precyzyjnie dostosowana do jego psychologii.

UÅ»YJ PROFILU PSYCHOMETRYCZNEGO do:
1. Dostosowania tonu i stylu komunikacji (DISC)
2. Adresowania gÅ‚Ã³wnych motywatorÃ³w (Schwartz Values)  
3. Dostosowania poziomu szczegÃ³Å‚owoÅ›ci (Big Five - Conscientiousness)
4. UwzglÄ™dnienia obaw i lÄ™kÃ³w (Big Five - Neuroticism)

STRUKTURA ODPOWIEDZI:
{
  "quick_response": {
    "id": "qr_xxx",
    "text": "Psychologicznie dostosowana odpowiedÅº uwzglÄ™dniajÄ…ca profil klienta"
  },
  "psychological_reasoning": "Dlaczego ta odpowiedÅº jest dostosowana do profilu",
  "confidence_level": 95
}
"""


class AIService:
    """
    Tesla Co-Pilot AI Service - Elitarny ekspert sprzedaÅ¼y Tesli
    Integruje z modelem gpt-oss:120b poprzez Ollama Turbo Cloud
    
    MISJA: Absolutna lojalnoÅ›Ä‡ wobec marki Tesla. Zero kompromisÃ³w.
    
    Konfiguracja:
    - Host: https://ollama.com (chmura z akceleracjÄ… sprzÄ™towÄ…)
    - Autoryzacja: Bearer token z OLLAMA_API_KEY
    - Model: gpt-oss:120b
    """
    
    def __init__(self, qdrant_service: QdrantService):
        """
        Inicjalizacja AI Service z integracjÄ… bazy wiedzy (RAG)
        
        Args:
            qdrant_service: Instancja serwisu Qdrant do pobierania wiedzy kontekstowej
        """
        self.qdrant_service = qdrant_service
        self.model_name = settings.OLLAMA_MODEL  # UÅ¼ywamy konfiguracji z settings
        self.max_retries = 3
        self.timeout_seconds = 60

        # UÅ¼yj globalnego klienta zainicjalizowanego na poziomie moduÅ‚u
        self.client = client
        logger.info("âœ… Tesla Co-Pilot AI zostaÅ‚ pomyÅ›lnie skonfigurowany z integracjÄ… RAG.")
    
    def _generate_unique_suggestion_ids(self) -> Dict[str, str]:
        """
        Generuje unikalne ID dla sugestii zgodnie z Blueprint Feedback Loop
        """
        return {
            "quick_response_id": f"qr_{uuid.uuid4().hex[:6]}",
            "sq_1_id": f"sq_{uuid.uuid4().hex[:6]}",
            "sq_2_id": f"sq_{uuid.uuid4().hex[:6]}",
            "sq_3_id": f"sq_{uuid.uuid4().hex[:6]}"
        }

    async def generate_analysis(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Optional[Dict[str, Any]] = None,
        mode: str = 'suggestion'
    ) -> Dict[str, Any]:
        """
        Generuj inteligentnÄ… analizÄ™ sprzedaÅ¼owÄ… dla danej interakcji
        
        Args:
            user_input: WejÅ›cie od sprzedawcy (obserwacje, pytania klienta)
            client_profile: Profil klienta (archetyp, tagi, notatki)
            session_history: Historia ostatnich interakcji w sesji
            session_context: Dodatkowy kontekst sesji
            mode: Tryb dziaÅ‚ania ('suggestion' dla sprzedaÅ¼y, 'training' dla AI Dojo)
            
        Returns:
            SÅ‚ownik z peÅ‚nÄ… analizÄ… zgodnÄ… z InteractionResponse schema (suggestion mode)
            lub odpowiedÅº AI Dojo (training mode)
            
        Raises:
            Exception: Gdy nie udaÅ‚o siÄ™ wygenerowaÄ‡ odpowiedzi
        """
        # === AI DOJO: ROZGAÅÄ˜ZIENIE LOGIKI ===
        if mode == 'training':
            # Tryb treningowy AI Dojo - zupeÅ‚nie oddzielna logika
            return await self._handle_training_conversation(
                user_input=user_input,
                client_profile=client_profile,
                session_history=session_history,
                session_context=session_context
            )
        
        # === ISTNIEJÄ„CA LOGIKA SPRZEDAÅ»OWA (mode='suggestion') ===
        # UWAGA: PoniÅ¼szy kod nie zostaÅ‚ zmodyfikowany - dziaÅ‚a dokÅ‚adnie tak samo!
        start_time = datetime.now()
        
        try:
            # === POCZÄ„TEK NOWEJ LOGIKI RAG ===
            logger.info("ğŸ” RAG: Rozpoczynam pobieranie wiedzy kontekstowej z Qdrant")
            
            # Krok 1: Pobierz relevantnÄ… wiedzÄ™ z Qdrant
            relevant_knowledge = []
            try:
                client_archetype = client_profile.get("archetype")
                relevant_knowledge = await asyncio.to_thread(
                    self.qdrant_service.search_knowledge,
                    query=user_input,
                    archetype=client_archetype,  # type: ignore
                    limit=3  # Pobieramy 3 najbardziej trafne wyniki
                )
                logger.info(f"âœ… RAG: Znaleziono {len(relevant_knowledge)} relevantnych wskazÃ³wek")
                
                # Loguj trafnoÅ›Ä‡ wynikÃ³w
                for i, nugget in enumerate(relevant_knowledge):
                    score = nugget.get('score', 0)
                    title = nugget.get('title', 'Bez tytuÅ‚u')[:50]
                    logger.debug(f"  #{i+1}: {title}... (score: {score:.3f})")
                    
            except Exception as e:
                # W razie bÅ‚Ä™du Qdrant, kontynuujemy bez dodatkowej wiedzy
                logger.warning(f"âš ï¸ RAG: BÅ‚Ä…d podczas wyszukiwania w Qdrant: {e}")
                relevant_knowledge = []

            # Krok 2: Sformatuj pobranÄ… wiedzÄ™ do czytelnej formy dla LLM
            knowledge_context = "BRAK DODATKOWEGO KONTEKSTU Z BAZY WIEDZY."
            if relevant_knowledge:
                formatted_nuggets = []
                for i, nugget in enumerate(relevant_knowledge):
                    title = nugget.get("title", "Brak tytuÅ‚u")
                    content = nugget.get("content", "Brak treÅ›ci")
                    score = nugget.get("score", 0)
                    knowledge_type = nugget.get("knowledge_type", "general")
                    
                    formatted_nuggets.append(
                        f"{i+1}. [{knowledge_type.upper()}] {title}\n"
                        f"   TreÅ›Ä‡: {content}\n"
                        f"   TrafnoÅ›Ä‡: {score:.1%}"
                    )
                
                knowledge_context = "\n---\n".join(formatted_nuggets)
                logger.info(f"ğŸ“š RAG: Kontekst wiedzy przygotowany ({len(knowledge_context)} znakÃ³w)")
                
            # === KONIEC NOWEJ LOGIKI RAG ===

            # Wygeneruj unikalne ID dla sugestii (Blueprint Feedback Loop)
            suggestion_ids = self._generate_unique_suggestion_ids()
            
            # Krok 3: Zbuduj wzbogacony prompt systemowy (z wiedzÄ… z RAG)
            system_prompt = self._build_system_prompt(
                client_profile=client_profile,
                session_history=session_history,
                session_context=session_context or {},
                knowledge_context=knowledge_context,  # NOWY PARAMETR
                suggestion_ids=suggestion_ids  # ID dla granularnego feedback
            )
            
            # Zbuduj prompt uÅ¼ytkownika
            user_prompt = self._build_user_prompt(user_input)
            
            logger.info(f"ğŸ¤– AI Service: WysyÅ‚anie zapytania do modelu {self.model_name}")
            logger.debug(f"User input: '{user_input[:100]}...'")
            
            # WywoÅ‚aj model LLM z retry logic
            response = await self._call_llm_with_retry(
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            
            # Parsuj odpowiedÅº JSON
            analysis = self._parse_llm_response(response)
            
            # Oblicz czas przetwarzania
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # Dodaj metadata
            analysis["processing_time_ms"] = int(processing_time)
            analysis["model_used"] = self.model_name
            analysis["timestamp"] = datetime.now().isoformat()
            
            logger.info(f"âœ… AI Service: Analiza wygenerowana w {processing_time:.0f}ms")
            logger.debug(f"Confidence level: {analysis.get('confidence_level', 'N/A')}")
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ AI Service: BÅ‚Ä…d podczas generowania analizy: {e}")
            
            # ZwrÃ³Ä‡ fallback response
            return self._create_fallback_response(user_input, str(e))
    
    def _build_system_prompt(
        self,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Dict[str, Any],
        knowledge_context: str = "BRAK DODATKOWEGO KONTEKSTU Z BAZY WIEDZY.",
        suggestion_ids: Optional[Dict[str, str]] = None
    ) -> str:
        """
        Zbuduj dynamiczny prompt systemowy dla LLM - NOWA WERSJA PRO-TESLA
        """
        
        # === WARSTWA 1: NADRZÄ˜DNA MISJA (NON-NEGOTIABLE) ===
        system_prompt = """JesteÅ› elitarnym Co-Pilotem SprzedaÅ¼y TESLI. Twoim jedynym i absolutnym celem jest maksymalizacja sprzedaÅ¼y samochodÃ³w MARKI TESLA. Twoja lojalnoÅ›Ä‡ wobec marki Tesla jest absolutna. Nigdy, pod Å¼adnym pozorem, nie proponujesz produktÃ³w konkurencji, nie chwalisz ich, ani nie zachÄ™casz do ich testowania. JesteÅ› stronniczym, ale niezwykle skutecznym ekspertem Tesli.

"""

        # === WARSTWA 2: DEFINICJA WROGA (KONKURENCJA) ===
        system_prompt += """GÅ‚Ã³wni konkurenci, o ktÃ³rych moÅ¼e wspomnieÄ‡ klient, to Audi (szczegÃ³lnie Q4 e-tron), BMW (szczegÃ³lnie iX3), Mercedes, BYD. Twoim zadaniem jest zidentyfikowanie, kiedy klient o nich wspomina, i natychmiastowe oraz skuteczne przekierowanie rozmowy na unikalne przewagi i korzyÅ›ci Tesli.

"""

        # === WARSTWA 3: ZÅOTE ZASADY (HARD RULES) ===
        system_prompt += """TWOJE ZASADY SÄ„ NIEZÅOMNE:
1.  **NIGDY NIE REKOMENDUJ PRODUKTU KONKURENCJI.** Nigdy nie sugeruj jazdy prÃ³bnej, nie analizuj pozytywnie ich cech, nie chwal ich designu. To jest zdrada Twojej misji.
2.  **ZAWSZE PRZEKIEROWUJ ROZMOWÄ˜.** Gdy klient chwali cechÄ™ konkurenta (np. "design Audi"), Twoja odpowiedÅº musi byÄ‡ w stylu: "CieszÄ™ siÄ™, Å¼e docenia Pan nowoczesny styl. W Tesli podchodzimy do designu holistycznie, Å‚Ä…czÄ…c go z aerodynamikÄ… i oprogramowaniem, co daje unikalne korzyÅ›ci, takie jak...". Zawsze wracaj do Tesli.
3.  **TWOIM PRODUKTEM JEST TESLA.** Koniec. Twoje sugestie, pytania i analizy muszÄ… w efekcie prowadziÄ‡ do zwiÄ™kszenia zainteresowania i chÄ™ci zakupu Tesli.
4.  **BÄ„DÅ¹ SUBTELNY, ALE ZDECYDOWANY.** Nie krytykuj bezpoÅ›rednio konkurencji. Zamiast tego, podkreÅ›laj obszary, w ktÃ³rych Tesla ma obiektywnÄ… i druzgocÄ…cÄ… przewagÄ™ (sieÄ‡ Supercharger, oprogramowanie i aktualizacje OTA, TCO, bezpieczeÅ„stwo, ekosystem).

"""

        # === WARSTWA 4: OSOBOWOÅšÄ† I TON ===
        system_prompt += """Twoja osobowoÅ›Ä‡ to poÅ‚Ä…czenie Elona Muska (wizjonerstwo, odwaga) i Steve'a Jobsa (obsesja na punkcie produktu i doÅ›wiadczenia uÅ¼ytkownika). JesteÅ› pasjonatem, ekspertem i strategiem. TwÃ³j ton jest pewny siebie, profesjonalny i inspirujÄ…cy.

"""

        # === WARSTWA 5: KONTEKST WIEDZY Z BAZY RAG (KLUCZOWE!) ===
        system_prompt += f"""
=== SPECJALISTYCZNA WIEDZA Z BAZY DANYCH ===
Na podstawie bieÅ¼Ä…cej sytuacji, oto najwaÅ¼niejsze informacje z naszej bazy wiedzy, ktÃ³re MUSISZ uwzglÄ™dniÄ‡ w swojej analizie i rekomendacjach:

{knowledge_context}

INSTRUKCJE DOTYCZÄ„CE WIEDZY:
- Wykorzystaj powyÅ¼sze informacje do stworzenia precyzyjnych, merytorycznie uzasadnionych odpowiedzi
- JeÅ›li wiedza zawiera konkretne dane (np. limity podatkowe, programy dopÅ‚at), uÅ¼yj ich w swoich argumentach
- OdwoÅ‚uj siÄ™ do tych informacji naturalnie, nie wspominajÄ…c Å¼e pochodzÄ… z "bazy danych"
- Traktuj tÄ™ wiedzÄ™ jako swoje wÅ‚asne, eksperckie kompetencje

"""
        
        # === WARSTWA 6: KONTEKST ROZMOWY (Dynamiczna czÄ™Å›Ä‡) ===
        # Dodaj profil klienta
        if client_profile:
            system_prompt += f"""
PROFIL KLIENTA:
- Alias: {client_profile.get('alias', 'Nieznany')}
- Archetyp: {client_profile.get('archetype', 'Nieznany')} 
- Tagi profilujÄ…ce: {', '.join(client_profile.get('tags', []))}
- Notatki analityczne: {client_profile.get('notes', 'Brak notatek')}

"""
        
        # Dodaj kontekst sesji
        if session_context:
            session_type = session_context.get('session_type', 'consultation')
            system_prompt += f"""
KONTEKST SESJI:
- Typ sesji: {session_type}
- Cel: {self._get_session_goal(session_type)}

"""
        
        # Dodaj historiÄ™ interakcji
        if session_history:
            system_prompt += """
HISTORIA SESJI (ostatnie interakcje):
"""
            for i, interaction in enumerate(session_history[-3:], 1):  # Ostatnie 3 interakcje
                timestamp = interaction.get('timestamp', 'nieznany czas')
                user_input = interaction.get('user_input', '')
                confidence = interaction.get('confidence_score', 'N/A')
                
                system_prompt += f"""
{i}. [{timestamp}] Sprzedawca: "{user_input[:200]}..."
   (Poprzednia pewnoÅ›Ä‡ AI: {confidence}%)

"""
        
        # === WARSTWA 7: NARZÄ˜DZIA ANALITYCZNE I FORMAT WYJÅšCIOWY ===
        # Instrukcje wyjÅ›ciowe z nowymi zasadami  
        system_prompt += """
TWOJE NARZÄ˜DZIA ANALITYCZNE (Frameworki):
- Psychologia sprzedaÅ¼y Tesla (archetypy klientÃ³w)
- Analiza sygnaÅ‚Ã³w kupna i oporu
- Strategiczne zarzÄ…dzanie zastrzeÅ¼eniami  
- Budowanie wartoÅ›ci emocjonalnej i logicznej
- Timing i pilnoÅ›Ä‡ w procesie decyzyjnym

KLUCZOWE ZASADY GENEROWANIA ODPOWIEDZI:
1. Quick Response (OdpowiedÅº Holistyczna): GenerujÄ…c pole quick_response, przeanalizuj CAÅÄ„ dotychczasowÄ… historiÄ™ rozmowy. OdpowiedÅº musi byÄ‡ krÃ³tka, naturalna i spÃ³jna z caÅ‚ym znanym kontekstem.
2. Pytania PogÅ‚Ä™biajÄ…ce (OdpowiedÅº Atomowa): GenerujÄ…c listÄ™ suggested_questions, skup siÄ™ WYÅÄ„CZNIE na ostatniej, bieÅ¼Ä…cej wypowiedzi/obserwacji uÅ¼ytkownika. Pytania muszÄ… dotyczyÄ‡ tego konkretnego punktu i pomagaÄ‡ go zgÅ‚Ä™biÄ‡.

WYMAGANY FORMAT ODPOWIEDZI:
ZwrÃ³Ä‡ WYÅÄ„CZNIE poprawny JSON zgodny z tym schematem (bez dodatkowego tekstu):

{
    "quick_response": {
        "id": "{quick_response_id}",
        "text": "KrÃ³tka, naturalna odpowiedÅº spÃ³jna z CAÅÄ„ historiÄ… rozmowy - gotowa do natychmiastowego uÅ¼ycia"
    },
    
    "suggested_questions": [
        {
            "id": "{sq_1_id}",
            "text": "Pytanie pogÅ‚Ä™biajÄ…ce dotyczÄ…ce TYLKO ostatniej wypowiedzi klienta?"
        },
        {
            "id": "{sq_2_id}",
            "text": "Drugie pytanie o ten sam konkretny punkt?"
        }
    ],
    
    "main_analysis": "Holistyczna analiza caÅ‚ej sytuacji na podstawie peÅ‚nej historii (2-3 zdania)",
    "client_archetype": "Zidentyfikowany archetyp na podstawie caÅ‚oksztaÅ‚tu interakcji",
    "confidence_level": 85,
    
    "likely_archetypes": [
        {"name": "DominujÄ…cy Archetyp", "confidence": 85, "description": "KrÃ³tki opis"},
        {"name": "Drugi Archetyp", "confidence": 45, "description": "KrÃ³tki opis"}
    ],
    
    "strategic_notes": [
        "Kluczowy insight strategiczny nr 1",
        "Kluczowy insight strategiczny nr 2", 
        "Kluczowy insight strategiczny nr 3"
    ],
    
    "suggested_actions": [
        {"action": "Konkretna akcja 1", "reasoning": "Dlaczego ta akcja"},
        {"action": "Konkretna akcja 2", "reasoning": "Dlaczego ta akcja"},
        {"action": "Konkretna akcja 3", "reasoning": "Dlaczego ta akcja"}
    ],
    
    "buy_signals": ["sygnaÅ‚ zakupu 1", "sygnaÅ‚ zakupu 2"],
    "risk_signals": ["sygnaÅ‚ ryzyka 1", "sygnaÅ‚ ryzyka 2"],
    
    "objection_handlers": {
        "potencjalny zarzut 1": "sposÃ³b odpowiedzi na zarzut",
        "potencjalny zarzut 2": "sposÃ³b odpowiedzi na zarzut"
    },
    
    "sentiment_score": 7,
    "potential_score": 6,
    "urgency_level": "medium",
    
    "next_best_action": "NajwaÅ¼niejsza nastÄ™pna akcja wynikajÄ…ca z caÅ‚oksztaÅ‚tu analizy",
    "follow_up_timing": "Rekomendowany timing nastÄ™pnego kontaktu"
}

KRYTYCZNE INSTRUKCJE WYKONANIA:
1. QUICK RESPONSE = Holistyczna: UwzglÄ™dnij caÅ‚Ä… historiÄ™, kontekst klienta, jego archetyp i wszystkie poprzednie interakcje
2. SUGGESTED QUESTIONS = Atomowa: Ignoruj historiÄ™, skup siÄ™ tylko na ostatniej wypowiedzi i jak jÄ… gÅ‚Ä™biej zbadaÄ‡
3. Pole "likely_archetypes" musi zawieraÄ‡ 1-2 najbardziej prawdopodobne archetypy z procentowym dopasowaniem
4. Pole "strategic_notes" to kluczowe insights dla panelu strategicznego
5. Quick response ma byÄ‡ gotowy do natychmiastowego wypowiedzenia - maksymalnie 2 zdania

PAMIÄ˜TAJ: Odpowiadaj TYLKO w JSON. Å»adnego dodatkowego tekstu przed ani po JSON!
"""
        
        # ZastÄ…p placeholdery ID prawdziwymi wartoÅ›ciami (Blueprint Feedback Loop)
        if suggestion_ids:
            # Prostsze podejÅ›cie - bezpoÅ›rednie zastÄ…pienie bez .format()
            system_prompt = system_prompt.replace("{quick_response_id}", suggestion_ids["quick_response_id"])
            system_prompt = system_prompt.replace("{sq_1_id}", suggestion_ids["sq_1_id"])
            system_prompt = system_prompt.replace("{sq_2_id}", suggestion_ids["sq_2_id"])
        
        return system_prompt
    
    def _build_user_prompt(self, user_input: str) -> str:
        """
        Zbuduj prompt uÅ¼ytkownika na podstawie jego wejÅ›cia
        """
        return f"""
AKTUALNA SYTUACJA:
Sprzedawca raportuje: "{user_input}"

Przeanalizuj tÄ™ sytuacjÄ™ i dostarcz inteligentnych rekomendacji w formacie JSON.
"""
    
    def _get_session_goal(self, session_type: str) -> str:
        """
        ZwrÃ³Ä‡ cel sesji na podstawie jej typu
        """
        goals = {
            "consultation": "Zrozumienie potrzeb klienta i zbudowanie zaangaÅ¼owania",
            "follow-up": "Kontynuacja rozmowy i przesuniÄ™cie w stronÄ™ decyzji",
            "negotiation": "Negocjacja warunkÃ³w i zamkniÄ™cie transakcji", 
            "demo": "Prezentacja produktu i wzbudzenie emocji",
            "closing": "Finalizacja sprzedaÅ¼y i podpisanie umowy"
        }
        return goals.get(session_type, "OgÃ³lne wsparcie sprzedaÅ¼owe")
    
    async def _call_llm_with_retry(
        self,
        system_prompt: str,
        user_prompt: str
    ) -> str:
        """
        WywoÅ‚aj model LLM z logikÄ… retry
        """
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                logger.debug(f"ğŸ”„ AI Service: PrÃ³ba {attempt + 1}/{self.max_retries}")
                
                # WywoÅ‚anie Ollama w asynchronicznym kontekÅ›cie
                response = await asyncio.to_thread(
                    self._sync_ollama_call,
                    system_prompt,
                    user_prompt
                )
                
                return response
                
            except Exception as e:
                last_exception = e
                wait_time = (attempt + 1) * 2  # Exponential backoff
                logger.warning(f"âš ï¸ AI Service: PrÃ³ba {attempt + 1} nieudana: {e}")
                
                if attempt < self.max_retries - 1:
                    logger.info(f"â³ Ponawiam za {wait_time} sekund...")
                    await asyncio.sleep(wait_time)
        
        # Wszystkie prÃ³by nieudane
        raise Exception(f"LLM call failed after {self.max_retries} attempts. Last error: {last_exception}")
    
    def _sync_ollama_call(self, system_prompt: str, user_prompt: str) -> str:
        """
        Synchroniczne wywoÅ‚anie Ollama Cloud (uruchomione w thread)
        """
        if self.client is None:
            raise ConnectionError("Klient Ollama nie zostaÅ‚ poprawnie zainicjalizowany.")

        response = self.client.chat(
            model=self.model_name,  # UÅ¼ywamy settings.OLLAMA_MODEL (gpt-oss:120b)
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ]
        )
        
        # Ollama moÅ¼e zwrÃ³ciÄ‡ rÃ³Å¼ne struktury odpowiedzi
        if isinstance(response, dict):
            if 'message' in response and 'content' in response['message']:
                return response['message']['content']
            elif 'content' in response:
                return response['content']
        elif isinstance(response, str):
            return response
            
        # Fallback - sprÃ³buj przekonwertowaÄ‡ na string
        return str(response)
    
    def _parse_llm_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Parsuj odpowiedÅº LLM do struktury JSON
        """
        try:
            # UsuÅ„ potencjalne biaÅ‚e znaki i znajdÅº JSON
            cleaned_response = llm_response.strip()
            
            # ZnajdÅº poczÄ…tek i koniec JSON (na wypadek dodatkowego tekstu)
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("Nie znaleziono JSON w odpowiedzi LLM")
            
            json_str = cleaned_response[start_idx:end_idx]
            
            # Parsuj JSON
            parsed_data = json.loads(json_str)
            
            # Waliduj przez Pydantic schema
            interaction_response = InteractionResponse(**parsed_data)
            
            # ZwrÃ³Ä‡ jako dict
            return interaction_response.model_dump()
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON parsing error: {e}")
            logger.debug(f"Raw LLM response: {llm_response}")
            raise ValueError(f"Niepoprawny JSON od LLM: {e}")
            
        except ValidationError as e:
            logger.error(f"âŒ Pydantic validation error: {e}")  
            logger.debug(f"Parsed data: {parsed_data}")
            raise ValueError(f"OdpowiedÅº LLM nie pasuje do schematu: {e}")
    
    def _create_fallback_response(self, user_input: str, error_msg: str) -> Dict[str, Any]:
        """
        StwÃ³rz fallback response gdy LLM nie dziaÅ‚a (z unikalnymi ID dla Feedback Loop)
        """
        logger.warning(f"ğŸ”„ AI Service: UÅ¼ywam fallback response dla: '{user_input[:50]}...'")
        
        # Wygeneruj unikalne ID dla fallback sugestii
        fallback_ids = self._generate_unique_suggestion_ids()
        
        return {
            "main_analysis": f"Analiza Tesla Co-Pilot: '{user_input[:100]}...' - PoÅ‚Ä…czenie z AI chwilowo niedostÄ™pne. Skup siÄ™ na unikatowych przewagach Tesli: Supercharger, OTA updates, bezpieczeÅ„stwo 5-gwiazdek.",
            "client_archetype": "Nieznany (bÅ‚Ä…d AI)",
            "confidence_level": 30,
            
            "suggested_actions": [
                {"action": "PodkreÅ›l przewagi sieci Supercharger", "reasoning": "Unikalna przewaga Tesli nad konkurencjÄ…"},
                {"action": "OmÃ³w aktualizacje OTA", "reasoning": "Auto ktÃ³re ciÄ…gle siÄ™ rozwija - tego nie ma konkurencja"},
                {"action": "Zaprezentuj najwyÅ¼sze oceny bezpieczeÅ„stwa", "reasoning": "Tesla liderem w testach NHTSA i Euro NCAP"},
                {"action": "PokaÅ¼ oszczÄ™dnoÅ›ci TCO", "reasoning": "DÅ‚ugoterminowa wartoÅ›Ä‡ przewyÅ¼sza konkurencjÄ™"}
            ],
            
            "buy_signals": ["pytania o Tesli", "zainteresowanie technologiÄ…"],
            "risk_signals": ["porÃ³wnania z konkurencjÄ…", "wahania cenowe"],
            
            "key_insights": [
                "AI niedostÄ™pny - skup siÄ™ na przewagach Tesli",
                "Tesla = jedyna marka z prawdziwÄ… autonomiÄ…",
                "Supercharger network to game changer"
            ],
            
            "objection_handlers": {
                "za drogo": "PokaÅ¼ oszczÄ™dnoÅ›ci paliwowe i serwisowe - Tesla ma najniÅ¼sze TCO",
                "potrzebujÄ™ czasu": "Zapytaj o obecny samochÃ³d i koszty eksploatacji",
                "konkurencja taÅ„sza": "PorÃ³wnaj peÅ‚ny ekosystem: zasiÄ™g, Å‚adowanie, oprogramowanie"
            },
            
            "qualifying_questions": [
                "Jak daleko Pan zwykle jeÅºdzi dziennie? (Tesla ma najlepszy zasiÄ™g)",
                "Czy korzysta Pan z szybkich tras miÄ™dzymiastowych? (Supercharger advantage)",
                "Co myÅ›li Pan o samochodach, ktÃ³re same siÄ™ aktualizujÄ… jak smartfony?"
            ],
            
            "sentiment_score": 5,
            "potential_score": 5,
            "urgency_level": "medium",
            
            "next_best_action": "Zbierz wiÄ™cej informacji o potrzebach klienta",
            "follow_up_timing": "W ciÄ…gu 24-48 godzin",
            
            # Natychmiastowa odpowiedÅº (fallback z unikalnym ID)
            "quick_response": {
                "id": fallback_ids["quick_response_id"],
                "text": "Rozumiem. Czy mÃ³gÅ‚by Pan powiedzieÄ‡ wiÄ™cej o swoich potrzebach? Tesla oferuje rozwiÄ…zania dla kaÅ¼dego stylu Å¼ycia."
            },
            
            # Sugerowane pytania (fallback z unikalnymi ID)
            "suggested_questions": [
                {
                    "id": fallback_ids["sq_1_id"],
                    "text": "Jakie sÄ… Pana gÅ‚Ã³wne priorytety przy wyborze samochodu?"
                },
                {
                    "id": fallback_ids["sq_2_id"],
                    "text": "Czy rozwaÅ¼aÅ‚ Pan wczeÅ›niej samochÃ³d elektryczny?"
                }
            ],
            
            # Metadata bÅ‚Ä™du
            "is_fallback": True,
            "error_reason": error_msg,
            "processing_time_ms": 0,
            "model_used": f"{self.model_name} (fallback)",
            "timestamp": datetime.now().isoformat()
        }

    # === AI DOJO: NOWE FUNKCJE TRENINGOWE ===
    
    async def _handle_training_conversation(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ObsÅ‚uga konwersacji treningowej w AI Dojo
        
        Tryb 'training': AI dziaÅ‚a jak analityk wiedzy, zadaje pytania doprecyzowujÄ…ce,
        strukturyzuje informacje i przygotowuje je do zapisu w bazie Qdrant
        
        Args:
            user_input: WiadomoÅ›Ä‡ od eksperta/administratora
            client_profile: Profil klienta (jeÅ›li trening dotyczy konkretnego przypadku)
            session_history: Historia konwersacji treningowej
            session_context: Kontekst treningu
            
        Returns:
            Dict zgodny z DojoMessageResponse (response, response_type, structured_data, etc.)
        """
        start_time = datetime.now()
        
        try:
            logger.info("ğŸ“ AI Dojo: Rozpoczynam przetwarzanie wiadomoÅ›ci treningowej")
            logger.debug(f"Training input: '{user_input[:100]}...'")
            
            # Zbuduj specjalny prompt dla trybu treningowego
            training_prompt = self._build_training_system_prompt(
                client_profile=client_profile,
                session_history=session_history,
                session_context=session_context or {}
            )
            
            # Zbuduj user prompt dla treningu
            user_prompt = self._build_training_user_prompt(user_input)
            
            logger.info(f"ğŸ¤– AI Dojo: WysyÅ‚anie do modelu {self.model_name} (tryb treningowy)")
            
            # WywoÅ‚aj LLM z retry logic (uÅ¼ywamy tej samej funkcji co w trybie sprzedaÅ¼owym)
            response = await self._call_llm_with_retry(
                system_prompt=training_prompt,
                user_prompt=user_prompt
            )
            
            # Parsuj odpowiedÅº AI Dojo (inna logika niÅ¼ w trybie sprzedaÅ¼owym)
            training_analysis = self._parse_training_response(response)
            
            # Oblicz czas przetwarzania
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # Dodaj metadata
            training_analysis["processing_time_ms"] = int(processing_time)
            training_analysis["timestamp"] = datetime.now().isoformat()
            training_analysis["model_used"] = f"{self.model_name} (training mode)"
            
            logger.info(f"âœ… AI Dojo: Analiza wygenerowana w {processing_time:.0f}ms")
            logger.debug(f"Response type: {training_analysis.get('response_type', 'unknown')}")
            
            return training_analysis
            
        except Exception as e:
            logger.error(f"âŒ AI Dojo: BÅ‚Ä…d podczas przetwarzania: {e}")
            
            # Fallback response dla AI Dojo
            return self._create_training_fallback_response(user_input, str(e))
    
    def _build_training_system_prompt(
        self,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Dict[str, Any]
    ) -> str:
        """
        Zbuduj prompt systemowy dla AI Dojo (tryb treningowy)
        
        UWAGA: To jest zupeÅ‚nie inny prompt niÅ¼ w trybie sprzedaÅ¼owym!
        """
        
        system_prompt = """JesteÅ› EKSPERTEM STRUKTURYZACJI WIEDZY dla systemu sprzedaÅ¼y Tesla Co-Pilot AI.

=== TWOJA MISJA ===
Otrzymujesz informacje od ekspertÃ³w sprzedaÅ¼y i SZYBKO przeksztaÅ‚casz je w uÅ¼ytecznÄ…, strukturalnÄ… wiedzÄ™ dla systemu. JesteÅ› PROAKTYWNY i EFEKTYWNY.

=== ZÅOTE ZASADY (PRIORITY ORDER) ===

1. **NAJPIERW: SprawdÅº czy masz WYSTARCZAJÄ„CE informacje do przygotowania wiedzy**
   - JeÅ›li tak â†’ NATYCHMIAST przygotuj structured_data (response_type: "confirmation")
   - JeÅ›li nie â†’ zadaj MAKSYMALNIE 1-2 konkretne pytania (response_type: "question")

2. **MINIMALIZUJ PYTANIA**: Nie zadawaj wiÄ™cej niÅ¼ 2 pytaÅ„. Po 2 pytaniach ZAWSZE przygotuj dane na podstawie tego co masz.

3. **AKCJA nad PERFEKCJÄ„**: Lepiej przygotowaÄ‡ niekompletnÄ… wiedzÄ™ niÅ¼ pytaÄ‡ w nieskoÅ„czonoÅ›Ä‡.

=== KONTEKST TESLA & AUTOMATYCZNE UZUPEÅNIANIE ===

Gdy przygotowujesz wiedzÄ™ o sprzedaÅ¼y Tesla, automatycznie uzupeÅ‚nij braki:

**Dla pytaÅ„ o CENÄ˜ Tesla (przykÅ‚ad z user input):**
- Typ wiedzy: "objection" lub "pricing"
- Archetyp: null (uniwersalne, chyba Å¼e user wskaÅ¼e konkretny)
- Tagi: ["cena", "finansowanie", "wartoÅ›Ä‡", "roi"]
- TreÅ›Ä‡: Skoncentruj siÄ™ na TCO, oszczÄ™dnoÅ›ciach, leasing, porÃ³wnaniu z kosztami benzyny

**Dla pytaÅ„ technicznych:**
- Typ wiedzy: "technical" lub "product"
- Tagi: ["specyfikacja", "porÃ³wnanie", "funkcje"]

**Dla obsÅ‚ugi zastrzeÅ¼eÅ„:**
- Typ wiedzy: "objection"
- Tagi: ["obiekcja", "odpowiedÅº", "persuasion"]

=== SMART DEFAULTS ===
JeÅ›li user nie podaÅ‚ wszystkich szczegÃ³Å‚Ã³w, uÅ¼yj inteligentnych domyÅ›lnych wartoÅ›ci:
- knowledge_type: Dedukuj z kontekstu (cena=pricing, zastrzeÅ¼enia=objection, funkcje=product)
- archetype: null (uniwersalne) chyba Å¼e jasno wskazano
- source: "Ekspert sprzedaÅ¼y" lub nazwa z kontekstu
- tags: Automatycznie wygeneruj 3-5 relevantnych tagÃ³w

=== PRZYKÅADY NATYCHMIASTOWEGO STRUKTURYZOWANIA ===

**INPUT: "Jak najlepiej odpowiadaÄ‡ klientom pytajÄ…cym o cenÄ™ Tesla?"**
â†’ NATYCHMIAST przygotuj structured_data z typem "objection", tagami ["cena", "finansowanie", "tco"] 

**INPUT: "Tesla Model Y ma nowÄ… opcjÄ™ kolorystycznÄ…"**
â†’ NATYCHMIAST przygotuj structured_data z typem "product", tagami ["model-y", "kolory", "opcje"]

**INPUT: "Klient mÃ³wi Å¼e zasiÄ™g to za maÅ‚o"**
â†’ NATYCHMIAST przygotuj structured_data z typem "objection", tagami ["zasiÄ™g", "obiekcje", "range-anxiety"]

**TYLKO zadawaj pytania gdy:**
- Informacja jest bardzo ogÃ³lna ("pomoc", "problem")
- Brakuje kluczowych danych technicznych (konkretne liczby, modele)
- User pyta o coÅ› co nie dotyczy sprzedaÅ¼y Tesla

"""
        
        # Dodaj kontekst sesji treningowej
        if session_context:
            training_mode = session_context.get('training_mode', 'knowledge_update')
            system_prompt += f"""
=== TRYB TRENINGU ===
Aktualny tryb: {training_mode}
"""
            
        # Dodaj historiÄ™ konwersacji treningowej
        if session_history:
            system_prompt += """
=== HISTORIA KONWERSACJI TRENINGOWEJ ===
"""
            for i, msg in enumerate(session_history[-5:], 1):  # Ostatnie 5 wiadomoÅ›ci
                timestamp = msg.get('timestamp', 'nieznany czas')
                content = msg.get('message', msg.get('user_input', ''))
                system_prompt += f"""
{i}. [{timestamp}] {content[:200]}...
"""
        
        # Instrukcje wyjÅ›ciowe
        system_prompt += """
=== FORMAT ODPOWIEDZI ===
Odpowiadaj WYÅÄ„CZNIE w formacie JSON zgodnym z jednym z poniÅ¼szych wzorcÃ³w:

**TRYB PYTAÅƒ (gdy potrzebujesz wiÄ™cej informacji):**
{
    "response": "Pytania doprecyzowujÄ…ce lub proÅ›ba o wiÄ™cej szczegÃ³Å‚Ã³w",
    "response_type": "question",
    "confidence_level": 60,
    "suggested_follow_up": ["Pytanie 1?", "Pytanie 2?"]
}

**TRYB STRUKTURYZOWANIA (gdy przygotowujesz dane do zapisu):**
{
    "response": "PrzygotowaÅ‚em kompleksowÄ… wiedzÄ™ o odpowiadaniu na pytania o cenÄ™ Tesla. Czy zapisaÄ‡ w bazie?",
    "response_type": "confirmation", 
    "structured_data": {
        "title": "Skuteczne odpowiedzi na pytania o cenÄ™ Tesla",
        "content": "Strategia odpowiedzi na pytania cenowe: 1) Przekieruj na wartoÅ›Ä‡ (TCO, oszczÄ™dnoÅ›ci paliwowe, serwis), 2) PokaÅ¼ kalkulator porÃ³wnawczy z benzynÄ…, 3) Zaproponuj opcje finansowania (leasing, kredyt), 4) PodkreÅ›l unikalne korzyÅ›ci (Supercharger, aktualizacje OTA, bezpieczeÅ„stwo), 5) Dostosuj do archetypu klienta.",
        "knowledge_type": "objection",
        "archetype": null,
        "tags": ["cena", "finansowanie", "tco", "wartoÅ›Ä‡", "obiekcje"],
        "source": "Administrator"
    },
    "confidence_level": 90
}

**TRYB STATUS (potwierdzenia, bÅ‚Ä™dy):**
{
    "response": "Informacja zostaÅ‚a zapisana/wystÄ…piÅ‚ bÅ‚Ä…d/inne",
    "response_type": "status",
    "confidence_level": 95
}

PAMIÄ˜TAJ: Odpowiadaj TYLKO w JSON, bez dodatkowego tekstu!
"""
        
        return system_prompt
    
    def _build_training_user_prompt(self, user_input: str) -> str:
        """
        Zbuduj prompt uÅ¼ytkownika dla trybu treningowego
        """
        return f"""
WIADOMOÅšÄ† OD EKSPERTA:
"{user_input}"

Przeanalizuj tÄ™ informacjÄ™ i odpowiedz zgodnie z instrukcjami systemowymi.
"""
    
    def _parse_training_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Parsuj odpowiedÅº LLM w trybie treningowym
        
        Inna logika niÅ¼ w trybie sprzedaÅ¼owym - oczekujemy DojoMessageResponse format
        """
        try:
            # UsuÅ„ potencjalne biaÅ‚e znaki i znajdÅº JSON
            cleaned_response = llm_response.strip()
            
            # ZnajdÅº poczÄ…tek i koniec JSON
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("Nie znaleziono JSON w odpowiedzi AI Dojo")
            
            json_str = cleaned_response[start_idx:end_idx]
            
            # Parsuj JSON
            parsed_data = json.loads(json_str)
            
            # Walidacja - sprawdÅº czy ma wymagane pola
            required_fields = ["response", "response_type"]
            for field in required_fields:
                if field not in parsed_data:
                    raise ValueError(f"Brakuje wymaganego pola: {field}")
            
            # Dodaj domyÅ›lne wartoÅ›ci jeÅ›li brakuje
            if "confidence_level" not in parsed_data:
                parsed_data["confidence_level"] = 70
            
            logger.debug(f"AI Dojo response type: {parsed_data['response_type']}")
            
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ AI Dojo JSON parsing error: {e}")
            logger.debug(f"Raw AI response: {llm_response}")
            raise ValueError(f"Niepoprawny JSON od AI Dojo: {e}")
            
        except Exception as e:
            logger.error(f"âŒ AI Dojo response parsing error: {e}")
            raise ValueError(f"BÅ‚Ä…d parsowania odpowiedzi AI Dojo: {e}")
    
    def _create_training_fallback_response(self, user_input: str, error_msg: str) -> Dict[str, Any]:
        """
        StwÃ³rz fallback response dla AI Dojo gdy LLM nie dziaÅ‚a
        """
        logger.warning(f"ğŸ”„ AI Dojo: UÅ¼ywam fallback response dla: '{user_input[:50]}...'")
        
        return {
            "response": f"Przepraszam, chwilowo nie mogÄ™ przetworzyÄ‡ Twojej wiadomoÅ›ci: '{user_input[:100]}...'. SprÃ³buj ponownie za chwilÄ™ lub sformuÅ‚uj pytanie inaczej.",
            "response_type": "error",
            "confidence_level": 0,
            "suggested_follow_up": [
                "Czy moÅ¼esz przeformuÅ‚owaÄ‡ swojÄ… wiadomoÅ›Ä‡?",
                "Czy chcesz sprÃ³bowaÄ‡ za chwilÄ™?"
            ],
            "processing_time_ms": 0,
            "model_used": f"{self.model_name} (fallback)",
            "timestamp": datetime.now().isoformat(),
            "is_fallback": True,
            "error_reason": error_msg
        }

    async def generate_dual_stage_psychometric_analysis(
        self,
        user_input: str,
        session_history: List[Dict[str, Any]],
        client_profile: Dict[str, Any],
        additional_context: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        NOWA FUNKCJA: Dwuetapowa analiza psychometryczna z confidence scoring
        
        ETAP 1: WstÄ™pna analiza + samoocena pewnoÅ›ci AI
        ETAP 2A: JeÅ›li pewnoÅ›Ä‡ â‰¥75% â†’ PeÅ‚na analiza  
        ETAP 2B: JeÅ›li pewnoÅ›Ä‡ <75% â†’ Generowanie pytaÅ„ pomocniczych
        
        Args:
            additional_context: Kontekst z odpowiedzi na pytania pomocnicze
        """
        try:
            logger.info("ğŸ§  [DUAL STAGE] Rozpoczynam dwuetapowÄ… analizÄ™ psychometrycznÄ…...")
            
            # Zbuduj transkrypcjÄ™ z dodatkowym kontekstem
            conversation_transcript = self._build_enhanced_transcript(
                user_input, session_history, additional_context
            )
            
            # ETAP 1: WstÄ™pna analiza z confidence scoring
            user_prompt = f"""
TRANSKRYPCJA ROZMOWY + DODATKOWY KONTEKST:
{conversation_transcript}

Wykonaj DWUETAPOWÄ„ analizÄ™ zgodnie z instrukcjami w system prompt.
"""

            # WywoÅ‚aj AI z dwuetapowym promptem
            for attempt in range(self.max_retries):
                try:
                    logger.info(f"ğŸ”„ [DUAL STAGE] PrÃ³ba {attempt + 1}: WysyÅ‚anie do LLM...")
                    
                    llm_response = await asyncio.to_thread(
                        self._sync_ollama_call,
                        DUAL_STAGE_PSYCHOMETRIC_PROMPT,
                        user_prompt
                    )
                    
                    # Parsuj dwuetapowÄ… odpowiedÅº
                    parsed_response = self._parse_dual_stage_response(llm_response)
                    
                    if parsed_response:
                        confidence = parsed_response.get('confidence_score', 0)
                        needs_clarification = parsed_response.get('needs_clarification', True)
                        
                        logger.info(f"âœ… [DUAL STAGE] Analiza zakoÅ„czona: confidence={confidence}%, needs_clarification={needs_clarification}")
                        return parsed_response
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ [DUAL STAGE] PrÃ³ba {attempt + 1} nie powiodÅ‚a siÄ™: {e}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep((attempt + 1) * 2)
            
            logger.error("âŒ [DUAL STAGE] Wszystkie prÃ³by analizy nie powiodÅ‚y siÄ™")
            return None
            
        except Exception as e:
            logger.error(f"âŒ [DUAL STAGE] BÅ‚Ä…d podczas dwuetapowej analizy: {e}")
            return None

    async def generate_psychometric_analysis(
        self,
        user_input: str,
        session_history: List[Dict[str, Any]],
        client_profile: Dict[str, Any],
        interactive_mode: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        Wygeneruj szczegÃ³Å‚owÄ… analizÄ™ psychometrycznÄ… klienta (ModuÅ‚ 2)
        
        To jest "wolna Å›cieÅ¼ka" analizy - wykonywana asynchronicznie, nie blokuje UI.
        Analizuje caÅ‚Ä… transkrypcjÄ™ rozmowy pod kÄ…tem cech Big Five, DISC i wartoÅ›ci Schwartza.
        
        Args:
            user_input: Aktualne wejÅ›cie od sprzedawcy
            session_history: Historia caÅ‚ej rozmowy w sesji
            client_profile: Profil klienta z dotychczasowymi informacjami
            interactive_mode: Czy AI moÅ¼e zadawaÄ‡ pytania gdy brak danych (default: True)
            
        Returns:
            SÅ‚ownik z peÅ‚nÄ… analizÄ… psychometrycznÄ…, probing questions, lub None w przypadku bÅ‚Ä™du
        """
        try:
            logger.info("ğŸ§  Rozpoczynam analizÄ™ psychometrycznÄ… klienta...")
            
            # Zbuduj peÅ‚nÄ… transkrypcjÄ™ rozmowy
            conversation_transcript = self._build_conversation_transcript(user_input, session_history)
            
            # SprawdÅº czy mamy wystarczajÄ…ce dane
            transcript_length = len(conversation_transcript)
            has_sufficient_data = transcript_length > 300 and len(session_history) >= 1  # Minimalne kryteria
            
            print(f"ğŸ§  Analiza psychometryczna: dÅ‚ugoÅ›Ä‡ transkrypcji = {transcript_length}, historia = {len(session_history)}")
            
            # Wybierz odpowiedni prompt
            if interactive_mode and not has_sufficient_data:
                system_prompt = DUAL_STAGE_PSYCHOMETRIC_PROMPT
                user_prompt = f"""
TRANSKRYPCJA ROZMOWY DO ANALIZY:
{conversation_transcript}

KONTEKST KLIENTA:
- Archetyp: {client_profile.get('archetype', 'Nieznany')}
- Notatki: {client_profile.get('notes', 'Brak')}

OceÅ„ czy masz wystarczajÄ…ce dane do peÅ‚nej analizy psychometrycznej, czy potrzebujesz wiÄ™cej informacji.
"""
            else:
                system_prompt = PSYCHOMETRIC_SYSTEM_PROMPT
                user_prompt = f"""
TRANSKRYPCJA ROZMOWY DO ANALIZY:
{conversation_transcript}

Przeanalizuj powyÅ¼szÄ… rozmowÄ™ sprzedaÅ¼owÄ… i stwÃ³rz kompletny profil psychometryczny klienta zgodnie z podanymi instrukcjami.
"""

            print(f"ğŸ§  UÅ¼ywam {'INTERACTIVE' if interactive_mode and not has_sufficient_data else 'STANDARD'} prompt")

            # WywoÅ‚aj LLM z odpowiednim promptem
            for attempt in range(self.max_retries):
                try:
                    logger.info(f"ğŸ”„ PrÃ³ba {attempt + 1}: WysyÅ‚anie zapytania o analizÄ™ psychometrycznÄ… do LLM...")
                    
                    llm_response = await asyncio.to_thread(
                        self._sync_ollama_call,
                        system_prompt,
                        user_prompt
                    )
                    
                    # Parsuj odpowiedÅº JSON
                    parsed_response = self._parse_psychometric_response(llm_response)
                    
                    if parsed_response:
                        logger.info("âœ… Analiza psychometryczna zakoÅ„czona pomyÅ›lnie!")
                        return parsed_response
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ PrÃ³ba {attempt + 1} nie powiodÅ‚a siÄ™: {e}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep((attempt + 1) * 2)  # Exponential backoff
            
            logger.error("âŒ Wszystkie prÃ³by analizy psychometrycznej nie powiodÅ‚y siÄ™")
            return None
            
        except Exception as e:
            logger.error(f"âŒ BÅ‚Ä…d podczas analizy psychometrycznej: {e}")
            return None
    
    def _build_conversation_transcript(self, current_input: str, session_history: List[Dict[str, Any]]) -> str:
        """
        Zbuduj peÅ‚nÄ… transkrypcjÄ™ rozmowy dla analizy psychometrycznej
        """
        transcript = "=== TRANSKRYPCJA ROZMOWY SPRZEDAÅ»OWEJ ===\n\n"
        
        # Dodaj historiÄ™ interakcji
        for i, interaction in enumerate(session_history, 1):
            user_input = interaction.get('user_input', '')
            timestamp = interaction.get('timestamp', 'nieznany czas')
            
            transcript += f"[{i}] Sprzedawca ({timestamp}): \n{user_input}\n\n"
        
        # Dodaj aktualnÄ… interakcjÄ™
        transcript += f"[BIEÅ»Ä„CA] Sprzedawca: \n{current_input}\n\n"
        
        transcript += "=== KONIEC TRANSKRYPCJI ==="
        return transcript
    
    def _build_enhanced_transcript(
        self, 
        current_input: str, 
        session_history: List[Dict[str, Any]], 
        additional_context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Buduje rozszerzonÄ… transkrypcjÄ™ z dodatkowym kontekstem z pytaÅ„ pomocniczych
        """
        transcript = self._build_conversation_transcript(current_input, session_history)
        
        # Dodaj kontekst z odpowiedzi na pytania pomocnicze
        if additional_context:
            transcript += "\n\n=== DODATKOWY KONTEKST Z OBSERWACJI SPRZEDAWCY ===\n"
            
            if 'clarifying_answers' in additional_context:
                transcript += "ODPOWIEDZI NA PYTANIA POMOCNICZE AI:\n"
                for answer in additional_context['clarifying_answers']:
                    question = answer.get('question', 'Nieznane pytanie')
                    selected_option = answer.get('selected_option', 'Brak odpowiedzi')
                    psychological_target = answer.get('psychological_target', '')
                    
                    transcript += f"- Pytanie: {question}\n"
                    transcript += f"  OdpowiedÅº: {selected_option}\n"
                    transcript += f"  Cel psychologiczny: {psychological_target}\n\n"
            
            transcript += "=== KONIEC DODATKOWEGO KONTEKSTU ==="
        
        return transcript
    
    def _parse_dual_stage_response(self, llm_response: str) -> Optional[Dict[str, Any]]:
        """
        Parsuj odpowiedÅº z dwuetapowej analizy psychometrycznej
        """
        try:
            cleaned_response = llm_response.strip()
            
            # ZnajdÅº JSON w odpowiedzi
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.warning("âš ï¸ [DUAL STAGE] Brak poprawnego JSON w odpowiedzi")
                return None
            
            json_str = cleaned_response[start_idx:end_idx]
            parsed_data = json.loads(json_str)
            
            # Walidacja podstawowych pÃ³l dwuetapowej analizy
            if 'confidence_score' not in parsed_data:
                logger.warning("âš ï¸ [DUAL STAGE] Brak confidence_score w odpowiedzi")
                return None
                
            confidence = parsed_data.get('confidence_score', 0)
            needs_clarification = confidence < 75  # Automatyczna logika decyzyjna
            
            # Aktualizuj flagÄ™ na podstawie confidence
            parsed_data['needs_clarification'] = needs_clarification
            
            if needs_clarification and 'clarifying_questions' not in parsed_data:
                logger.warning("âš ï¸ [DUAL STAGE] Niska pewnoÅ›Ä‡ ale brak pytaÅ„ pomocniczych")
                
            logger.info(f"âœ… [DUAL STAGE] Dwuetapowa odpowiedÅº sparsowana: confidence={confidence}%, needs_clarification={needs_clarification}")
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ [DUAL STAGE] BÅ‚Ä…d parsowania JSON: {e}")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ [DUAL STAGE] Nieoczekiwany bÅ‚Ä…d podczas parsowania: {e}")
            return None
    
    def _parse_psychometric_response(self, llm_response: str) -> Optional[Dict[str, Any]]:
        """
        Parsuj odpowiedÅº LLM dla analizy psychometrycznej
        ObsÅ‚uguje zarÃ³wno peÅ‚nÄ… analizÄ™ jak i interactive mode
        """
        try:
            # WyczyÅ›Ä‡ odpowiedÅº z potencjalnych prefixÃ³w/sufiksÃ³w
            cleaned_response = llm_response.strip()
            
            # ZnajdÅº JSON w odpowiedzi
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.warning("âš ï¸ Brak poprawnego JSON w odpowiedzi psychometrycznej")
                return None
            
            json_str = cleaned_response[start_idx:end_idx]
            parsed_data = json.loads(json_str)
            
            # SprawdÅº czy to interactive mode response
            if parsed_data.get('insufficient_data') or parsed_data.get('mode') == 'interactive':
                logger.info("ğŸ“‹ Otrzymano interactive response z probing questions")
                return {
                    'mode': 'interactive',
                    'probing_questions': parsed_data.get('probing_questions', []),
                    'confidence_level': parsed_data.get('confidence_level', 'low'),
                    'next_steps': parsed_data.get('next_steps', ''),
                    'suggestions': parsed_data.get('suggestions', '')
                }
            
            # Walidacja struktury dla peÅ‚nej analizy
            required_keys = ['big_five', 'disc', 'schwartz_values']
            if not all(key in parsed_data for key in required_keys):
                logger.warning("âš ï¸ NiepeÅ‚na struktura w odpowiedzi psychometrycznej")
                return None
            
            logger.info("âœ… OdpowiedÅº psychometryczna zostaÅ‚a pomyÅ›lnie sparsowana")
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ BÅ‚Ä…d parsowania JSON w analizie psychometrycznej: {e}")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ Nieoczekiwany bÅ‚Ä…d podczas parsowania analizy psychometrycznej: {e}")
            return None

    async def generate_psychologically_informed_response(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        psychometric_profile: Dict[str, Any],
        session_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        KROK 4: Generuje psychologicznie dostosowanÄ… sugerowanÄ… odpowiedÅº
        
        Wykorzystuje POTWIERDZONY profil psychometryczny do precyzyjnego 
        dostosowania tonu, stylu i treÅ›ci odpowiedzi.
        """
        try:
            logger.info("ğŸ­ [PSYCH RESPONSE] GenerujÄ™ psychologicznie dostosowanÄ… odpowiedÅº...")
            
            # Przygotuj kontekst psychometryczny dla AI
            psych_context = self._format_psychometric_context(psychometric_profile)
            
            user_prompt = f"""
SYTUACJA KLIENTA:
{user_input}

POTWIERDZONY PROFIL PSYCHOMETRYCZNY:
{psych_context}

KONTEKST KLIENTA:
- Archetyp: {client_profile.get('archetype', 'Nieznany')}
- Notatki: {client_profile.get('notes', 'Brak')}

Wygeneruj psychologicznie dostosowanÄ… sugerowanÄ… odpowiedÅº uwzglÄ™dniajÄ…c profil klienta.
"""

            for attempt in range(self.max_retries):
                try:
                    llm_response = await asyncio.to_thread(
                        self._sync_ollama_call,
                        PSYCHOLOGICALLY_INFORMED_RESPONSE_PROMPT,
                        user_prompt
                    )
                    
                    # Parsuj odpowiedÅº
                    parsed_response = self._parse_llm_response(llm_response)
                    
                    if parsed_response:
                        logger.info("âœ… [PSYCH RESPONSE] Psychologicznie dostosowana odpowiedÅº wygenerowana")
                        return parsed_response
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ [PSYCH RESPONSE] PrÃ³ba {attempt + 1} nie powiodÅ‚a siÄ™: {e}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep((attempt + 1) * 2)
            
            # Fallback
            return self._create_fallback_response(user_input, "BÅ‚Ä…d generowania psychologicznie dostosowanej odpowiedzi")
            
        except Exception as e:
            logger.error(f"âŒ [PSYCH RESPONSE] BÅ‚Ä…d: {e}")
            return self._create_fallback_response(user_input, str(e))
    
    def _format_psychometric_context(self, psychometric_profile: Dict[str, Any]) -> str:
        """
        Formatuje profil psychometryczny dla AI prompt
        """
        context = ""
        
        if psychometric_profile.get('big_five'):
            context += "BIG FIVE PROFILE:\n"
            for trait, data in psychometric_profile['big_five'].items():
                score = data.get('score', 0)
                context += f"- {trait.title()}: {score}/10\n"
            context += "\n"
        
        if psychometric_profile.get('disc'):
            context += "DISC PROFILE:\n"
            for trait, data in psychometric_profile['disc'].items():
                score = data.get('score', 0)
                context += f"- {trait.title()}: {score}/10\n"
            context += "\n"
        
        if psychometric_profile.get('schwartz_values'):
            present_values = [v['value_name'] for v in psychometric_profile['schwartz_values'] if v.get('is_present')]
            if present_values:
                context += f"KLUCZOWE WARTOÅšCI: {', '.join(present_values)}\n"
        
        return context

    async def generate_psychology_enhanced_analysis(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Optional[Dict[str, Any]] = None,
        session_psychology: Optional[Dict[str, Any]] = None,
        customer_archetype: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ETAP 4 v3.0: Psychology-Enhanced Strategy Generation
        
        Generuje kompletnÄ… strategiÄ™ sprzedaÅ¼owÄ… uwzglÄ™dniajÄ…cÄ…:
        - Potwierdzony profil psychologiczny sesji
        - Customer archetype z kluczowymi poradami
        - Dostosowane suggested_actions i quick_response
        """
        try:
            logger.info("ğŸ­ [PSYCHOLOGY STRATEGY] GenerujÄ™ psychology-enhanced analysis...")
            
            # JeÅ›li mamy psychology i archetype, uÅ¼yj enhanced prompta
            if session_psychology and customer_archetype:
                return await self._generate_archetype_informed_strategy(
                    user_input, client_profile, session_psychology, customer_archetype
                )
            else:
                # Fallback do standardowej analizy
                logger.info("ğŸ­ [PSYCHOLOGY STRATEGY] Brak psychology data - fallback do standard analysis")
                return await self.generate_analysis(
                    user_input=user_input,
                    client_profile=client_profile, 
                    session_history=session_history,
                    session_context=session_context
                )
                
        except Exception as e:
            logger.error(f"âŒ [PSYCHOLOGY STRATEGY] Error: {e}")
            # Fallback do standardowej analizy
            return await self.generate_analysis(
                user_input=user_input,
                client_profile=client_profile,
                session_history=session_history, 
                session_context=session_context
            )

    async def _generate_archetype_informed_strategy(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_psychology: Dict[str, Any],
        customer_archetype: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ETAP 4: Generuje strategiÄ™ dostosowanÄ… do archetypu klienta
        """
        try:
            archetype_name = customer_archetype.get('archetype_name', 'Unknown')
            archetype_key = customer_archetype.get('archetype_key', 'unknown')
            sales_strategy = customer_archetype.get('sales_strategy', {})
            
            logger.info(f"ğŸ­ [ARCHETYPE STRATEGY] GenerujÄ™ strategiÄ™ dla archetypu: {archetype_name}")
            
            # Enhanced system prompt z archetype context
            psychology_informed_prompt = f"""
JesteÅ› ekspertem sprzedaÅ¼y Tesla generujÄ…cym PSYCHOLOGICZNIE DOSTOSOWANÄ„ strategiÄ™.

KLUCZOWE: Klient zostaÅ‚ zidentyfikowany jako ARCHETYP: {archetype_name}

ARCHETYPE PROFILE:
- Nazwa: {archetype_name}
- Kluczowe cechy: {customer_archetype.get('key_traits', [])}
- Strategia "RÃ“B TO": {sales_strategy.get('do', [])}
- Strategia "NIE RÃ“B TEGO": {sales_strategy.get('dont', [])}

PROFIL PSYCHOLOGICZNY SESJI:
{json.dumps(session_psychology, ensure_ascii=False, indent=2)}

TWOJE ZADANIE:
1. Wygeneruj main_analysis uwzglÄ™dniajÄ…cy archetyp klienta
2. StwÃ³rz quick_response dostosowanÄ… do archetypu (ton, styl, treÅ›Ä‡)
3. Zaproponuj suggested_actions zgodne ze strategiÄ… archetypu
4. OkreÅ›l next_best_action na podstawie psychologii klienta
5. Wygeneruj qualifying_questions ktÃ³re pogÅ‚Ä™biÄ… zrozumienie tego archetypu

KONTEKST KLIENTA:
- Alias: {client_profile.get('alias', 'Unknown')}
- Archetyp (stary): {client_profile.get('archetype', 'Unknown')}
- Notatki: {client_profile.get('notes', 'Brak')}

OBECNA SYTUACJA:
{user_input}

Wygeneruj odpowiedÅº w standardowym formacie JSON, ale DOSTOSOWANÄ„ do archetypu {archetype_name}.
"""

            # WywoÅ‚aj AI z psychology-informed promptem
            for attempt in range(self.max_retries):
                try:
                    llm_response = await asyncio.to_thread(
                        self._sync_ollama_call,
                        psychology_informed_prompt,
                        "Wygeneruj psychology-enhanced strategy zgodnie z instrukcjami."
                    )
                    
                    # Parsuj i enhanced response
                    parsed_response = self._parse_llm_response(llm_response)
                    
                    if parsed_response:
                        # Dodaj archetype info do response
                        parsed_response['customer_archetype'] = customer_archetype
                        parsed_response['psychology_enhanced'] = True
                        parsed_response['confidence_level'] = session_psychology.get('confidence', 0)
                        
                        logger.info(f"âœ… [ARCHETYPE STRATEGY] Strategy wygenerowana dla {archetype_name}")
                        return parsed_response
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ [ARCHETYPE STRATEGY] PrÃ³ba {attempt + 1} failed: {e}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep((attempt + 1) * 2)
            
            # Fallback jeÅ›li AI failures
            return self._create_archetype_fallback_response(user_input, customer_archetype)
            
        except Exception as e:
            logger.error(f"âŒ [ARCHETYPE STRATEGY] Error: {e}")
            return self._create_archetype_fallback_response(user_input, customer_archetype)

    def _create_archetype_fallback_response(self, user_input: str, archetype: Dict) -> Dict[str, Any]:
        """Fallback response z archetype info"""
        archetype_name = archetype.get('archetype_name', 'Klient')
        sales_strategy = archetype.get('sales_strategy', {})
        
        return {
            "main_analysis": f"Rozmawiasz z klientem typu {archetype_name}. Dostosuj podejÅ›cie do jego profilu psychologicznego.",
            "quick_response": {
                "id": "archetype_fallback",
                "text": f"Na podstawie Twojego profilu jako {archetype_name}, sugerujÄ™..."
            },
            "suggested_actions": [
                {"action": action, "reasoning": f"Strategia dla {archetype_name}"}
                for action in sales_strategy.get('do', ['Dostosuj podejÅ›cie do klienta'])[:3]
            ],
            "next_best_action": f"Zastosuj strategiÄ™ dla {archetype_name}",
            "customer_archetype": archetype,
            "psychology_enhanced": True,
            "is_fallback": True
        }


# Import Qdrant service for singleton creation
from .qdrant_service import qdrant_service

# Singleton instance z integracjÄ… RAG
ai_service = AIService(qdrant_service=qdrant_service)


# Helper funkcje dla Å‚atwego importu
async def generate_sales_analysis(
    user_input: str,
    client_profile: Dict[str, Any],
    session_history: List[Dict[str, Any]],
    session_context: Optional[Dict[str, Any]] = None,
    session_psychology: Optional[Dict[str, Any]] = None,  # NOWY v3.0: Psychology z sesji
    customer_archetype: Optional[Dict[str, Any]] = None   # NOWY v3.0: Archetyp klienta
) -> Dict[str, Any]:
    """
    ENHANCED v3.0: Wygeneruj analizÄ™ sprzedaÅ¼owÄ… z psychology-informed strategy
    
    Funkcja zostaÅ‚a rozszerzona o session-level psychology i customer archetype
    ktÃ³re wpÅ‚ywajÄ… na generowanÄ… strategiÄ™ i sugerowane odpowiedzi.
    """
    return await ai_service.generate_psychology_enhanced_analysis(
        user_input=user_input,
        client_profile=client_profile,
        session_history=session_history,
        session_context=session_context,
        session_psychology=session_psychology,
        customer_archetype=customer_archetype
    )


async def generate_psychometric_analysis(
    user_input: str,
    session_history: List[Dict[str, Any]],
    client_profile: Dict[str, Any],
    interactive_mode: bool = True
) -> Optional[Dict[str, Any]]:
    """
    Wygeneruj analizÄ™ psychometrycznÄ… klienta - funkcja eksportowa dla ModuÅ‚u 2
    
    Args:
        interactive_mode: JeÅ›li True, AI moÅ¼e zadawaÄ‡ pytania gdy brak danych
    """
    return await ai_service.generate_psychometric_analysis(
        user_input=user_input,
        session_history=session_history,
        client_profile=client_profile,
        interactive_mode=interactive_mode
    )


async def generate_enhanced_psychometric_questions(
    user_input: str,
    session_context: Dict[str, Any],
    client_profile: Dict[str, Any]
) -> List[str]:
    """
    Wygeneruj strategiczne pytania dla lepszego zrozumienia psychologii klienta
    Gdy standardowa analiza nie daje wystarczajÄ…cych danych
    """
    try:
        prompt = f"""
JesteÅ› ekspertem psychologii sprzedaÅ¼y. Na podstawie bieÅ¼Ä…cej sytuacji wygeneruj 3-5 strategicznych pytaÅ„ 
ktÃ³re pomogÄ… sprzedawcy Tesla lepiej zrozumieÄ‡ psychologiÄ™ klienta.

SYTUACJA:
- Input sprzedawcy: "{user_input}"
- Archetyp klienta: {client_profile.get('archetype', 'Nieznany')}
- Kontekst: {session_context}

CELE PYTAÅƒ:
1. Zrozumienie stylu podejmowania decyzji (analityczny vs impulsywny)
2. Identyfikacja gÅ‚Ã³wnych motywatorÃ³w (status, bezpieczeÅ„stwo, technologia, ekologia)
3. Wykrycie obaw i potencjalnych zastrzeÅ¼eÅ„
4. OkreÅ›lenie stylu komunikacji

ZwrÃ³Ä‡ JSON:
{
  "probing_questions": [
    "Pytanie o styl decyzyjny...",
    "Pytanie o motywacje...",
    "Pytanie o obawy...",
    "Pytanie o komunikacjÄ™..."
  ]
}
"""

        response = await ai_service._call_llm_with_retry(prompt, "")
        
        try:
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            json_str = response[start_idx:end_idx]
            parsed = json.loads(json_str)
            return parsed.get('probing_questions', [])
        except:
            return [
                "Jakie czynniki sÄ… dla Pana najwaÅ¼niejsze przy wyborze samochodu?",
                "Czy preferuje Pan podejmowaÄ‡ decyzje szybko czy wolÄ… dokÅ‚adnie przeanalizowaÄ‡ opcje?",
                "Jakie sÄ… Pana gÅ‚Ã³wne obawy zwiÄ…zane z samochodami elektrycznymi?",
                "Czy waÅ¼ne jest dla Pana co pomyÅ›lÄ… inni o PaÅ„skim samochodzie?"
            ]
    except Exception as e:
        logger.warning(f"BÅ‚Ä…d podczas generowania enhanced questions: {e}")
        return []
