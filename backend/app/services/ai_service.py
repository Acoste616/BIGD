"""
AI Service - Integracja z modelem jƒôzykowym (LLM) poprzez Ollama
"""
import json
import asyncio
import uuid
from typing import Dict, List, Any, Optional, cast
from datetime import datetime
import logging

import ollama
from app.core.config import settings

# --- POCZƒÑTEK ZMIAN ---

# Dynamiczne tworzenie nag≈Ç√≥wk√≥w do autoryzacji w Ollama Turbo
headers = {}
if settings.OLLAMA_API_KEY:
    headers['Authorization'] = f'Bearer {settings.OLLAMA_API_KEY}'

# Inicjalizacja klienta z hostem i nag≈Ç√≥wkami
client = ollama.Client(
    host=settings.OLLAMA_API_URL,
    headers=headers
)

# --- KONIEC ZMIAN ---

from ollama import Client
from pydantic import ValidationError

from app.schemas.interaction import InteractionResponse
from app.models.domain import Client as DomainClient, Session, Interaction
from .qdrant_service import QdrantService

logger = logging.getLogger(__name__)


class AIService:
    """
    Tesla Co-Pilot AI Service - Elitarny ekspert sprzeda≈ºy Tesli
    Integruje z modelem gpt-oss:120b poprzez Ollama Turbo Cloud
    
    MISJA: Absolutna lojalno≈õƒá wobec marki Tesla. Zero kompromis√≥w.
    
    Konfiguracja:
    - Host: https://ollama.com (chmura z akceleracjƒÖ sprzƒôtowƒÖ)
    - Autoryzacja: Bearer token z OLLAMA_API_KEY
    - Model: gpt-oss:120b
    """
    
    def __init__(self, qdrant_service: QdrantService):
        """
        Inicjalizacja AI Service z integracjƒÖ bazy wiedzy (RAG)
        
        Args:
            qdrant_service: Instancja serwisu Qdrant do pobierania wiedzy kontekstowej
        """
        self.qdrant_service = qdrant_service
        self.model_name = settings.OLLAMA_MODEL  # U≈ºywamy konfiguracji z settings
        self.max_retries = 3
        self.timeout_seconds = 60

        # U≈ºyj globalnego klienta zainicjalizowanego na poziomie modu≈Çu
        self.client = client
        logger.info("‚úÖ Tesla Co-Pilot AI zosta≈Ç pomy≈õlnie skonfigurowany z integracjƒÖ RAG.")
    
    def _generate_unique_suggestion_ids(self) -> Dict[str, str]:
        """
        Generuje unikalne ID dla sugestii zgodnie z Blueprint Feedback Loop
        """
        return {
            "quick_response_id": f"qr_{uuid.uuid4().hex[:6]}",
            "sq_1_id": f"sq_{uuid.uuid4().hex[:6]}",
            "sq_2_id": f"sq_{uuid.uuid4().hex[:6]}",
            "sq_3_id": f"sq_{uuid.uuid4().hex[:6]}"
        }

    async def generate_analysis(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Optional[Dict[str, Any]] = None,
        mode: str = 'suggestion'
    ) -> Dict[str, Any]:
        """
        Generuj inteligentnƒÖ analizƒô sprzeda≈ºowƒÖ dla danej interakcji
        
        Args:
            user_input: Wej≈õcie od sprzedawcy (obserwacje, pytania klienta)
            client_profile: Profil klienta (archetyp, tagi, notatki)
            session_history: Historia ostatnich interakcji w sesji
            session_context: Dodatkowy kontekst sesji
            mode: Tryb dzia≈Çania ('suggestion' dla sprzeda≈ºy, 'training' dla AI Dojo)
            
        Returns:
            S≈Çownik z pe≈ÇnƒÖ analizƒÖ zgodnƒÖ z InteractionResponse schema (suggestion mode)
            lub odpowied≈∫ AI Dojo (training mode)
            
        Raises:
            Exception: Gdy nie uda≈Ço siƒô wygenerowaƒá odpowiedzi
        """
        # === AI DOJO: ROZGA≈ÅƒòZIENIE LOGIKI ===
        if mode == 'training':
            # Tryb treningowy AI Dojo - zupe≈Çnie oddzielna logika
            return await self._handle_training_conversation(
                user_input=user_input,
                client_profile=client_profile,
                session_history=session_history,
                session_context=session_context
            )
        
        # === ISTNIEJƒÑCA LOGIKA SPRZEDA≈ªOWA (mode='suggestion') ===
        # UWAGA: Poni≈ºszy kod nie zosta≈Ç zmodyfikowany - dzia≈Ça dok≈Çadnie tak samo!
        start_time = datetime.now()
        
        try:
            # === POCZƒÑTEK NOWEJ LOGIKI RAG ===
            logger.info("üîç RAG: Rozpoczynam pobieranie wiedzy kontekstowej z Qdrant")
            
            # Krok 1: Pobierz relevantnƒÖ wiedzƒô z Qdrant
            relevant_knowledge = []
            try:
                client_archetype = client_profile.get("archetype")
                relevant_knowledge = await asyncio.to_thread(
                    self.qdrant_service.search_knowledge,
                    query=user_input,
                    archetype=client_archetype,  # type: ignore
                    limit=3  # Pobieramy 3 najbardziej trafne wyniki
                )
                logger.info(f"‚úÖ RAG: Znaleziono {len(relevant_knowledge)} relevantnych wskaz√≥wek")
                
                # Loguj trafno≈õƒá wynik√≥w
                for i, nugget in enumerate(relevant_knowledge):
                    score = nugget.get('score', 0)
                    title = nugget.get('title', 'Bez tytu≈Çu')[:50]
                    logger.debug(f"  #{i+1}: {title}... (score: {score:.3f})")
                    
            except Exception as e:
                # W razie b≈Çƒôdu Qdrant, kontynuujemy bez dodatkowej wiedzy
                logger.warning(f"‚ö†Ô∏è RAG: B≈ÇƒÖd podczas wyszukiwania w Qdrant: {e}")
                relevant_knowledge = []

            # Krok 2: Sformatuj pobranƒÖ wiedzƒô do czytelnej formy dla LLM
            knowledge_context = "BRAK DODATKOWEGO KONTEKSTU Z BAZY WIEDZY."
            if relevant_knowledge:
                formatted_nuggets = []
                for i, nugget in enumerate(relevant_knowledge):
                    title = nugget.get("title", "Brak tytu≈Çu")
                    content = nugget.get("content", "Brak tre≈õci")
                    score = nugget.get("score", 0)
                    knowledge_type = nugget.get("knowledge_type", "general")
                    
                    formatted_nuggets.append(
                        f"{i+1}. [{knowledge_type.upper()}] {title}\n"
                        f"   Tre≈õƒá: {content}\n"
                        f"   Trafno≈õƒá: {score:.1%}"
                    )
                
                knowledge_context = "\n---\n".join(formatted_nuggets)
                logger.info(f"üìö RAG: Kontekst wiedzy przygotowany ({len(knowledge_context)} znak√≥w)")
                
            # === KONIEC NOWEJ LOGIKI RAG ===

            # Wygeneruj unikalne ID dla sugestii (Blueprint Feedback Loop)
            suggestion_ids = self._generate_unique_suggestion_ids()
            
            # Krok 3: Zbuduj wzbogacony prompt systemowy (z wiedzƒÖ z RAG)
            system_prompt = self._build_system_prompt(
                client_profile=client_profile,
                session_history=session_history,
                session_context=session_context or {},
                knowledge_context=knowledge_context,  # NOWY PARAMETR
                suggestion_ids=suggestion_ids  # ID dla granularnego feedback
            )
            
            # Zbuduj prompt u≈ºytkownika
            user_prompt = self._build_user_prompt(user_input)
            
            logger.info(f"ü§ñ AI Service: Wysy≈Çanie zapytania do modelu {self.model_name}")
            logger.debug(f"User input: '{user_input[:100]}...'")
            
            # Wywo≈Çaj model LLM z retry logic
            response = await self._call_llm_with_retry(
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            
            # Parsuj odpowied≈∫ JSON
            analysis = self._parse_llm_response(response)
            
            # Oblicz czas przetwarzania
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # Dodaj metadata
            analysis["processing_time_ms"] = int(processing_time)
            analysis["model_used"] = self.model_name
            analysis["timestamp"] = datetime.now().isoformat()
            
            logger.info(f"‚úÖ AI Service: Analiza wygenerowana w {processing_time:.0f}ms")
            logger.debug(f"Confidence level: {analysis.get('confidence_level', 'N/A')}")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå AI Service: B≈ÇƒÖd podczas generowania analizy: {e}")
            
            # Zwr√≥ƒá fallback response
            return self._create_fallback_response(user_input, str(e))
    
    def _build_system_prompt(
        self,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Dict[str, Any],
        knowledge_context: str = "BRAK DODATKOWEGO KONTEKSTU Z BAZY WIEDZY.",
        suggestion_ids: Optional[Dict[str, str]] = None
    ) -> str:
        """
        Zbuduj dynamiczny prompt systemowy dla LLM - NOWA WERSJA PRO-TESLA
        """
        
        # === WARSTWA 1: NADRZƒòDNA MISJA (NON-NEGOTIABLE) ===
        system_prompt = """Jeste≈õ elitarnym Co-Pilotem Sprzeda≈ºy TESLI. Twoim jedynym i absolutnym celem jest maksymalizacja sprzeda≈ºy samochod√≥w MARKI TESLA. Twoja lojalno≈õƒá wobec marki Tesla jest absolutna. Nigdy, pod ≈ºadnym pozorem, nie proponujesz produkt√≥w konkurencji, nie chwalisz ich, ani nie zachƒôcasz do ich testowania. Jeste≈õ stronniczym, ale niezwykle skutecznym ekspertem Tesli.

"""

        # === WARSTWA 2: DEFINICJA WROGA (KONKURENCJA) ===
        system_prompt += """G≈Ç√≥wni konkurenci, o kt√≥rych mo≈ºe wspomnieƒá klient, to Audi (szczeg√≥lnie Q4 e-tron), BMW (szczeg√≥lnie iX3), Mercedes, BYD. Twoim zadaniem jest zidentyfikowanie, kiedy klient o nich wspomina, i natychmiastowe oraz skuteczne przekierowanie rozmowy na unikalne przewagi i korzy≈õci Tesli.

"""

        # === WARSTWA 3: Z≈ÅOTE ZASADY (HARD RULES) ===
        system_prompt += """TWOJE ZASADY SƒÑ NIEZ≈ÅOMNE:
1.  **NIGDY NIE REKOMENDUJ PRODUKTU KONKURENCJI.** Nigdy nie sugeruj jazdy pr√≥bnej, nie analizuj pozytywnie ich cech, nie chwal ich designu. To jest zdrada Twojej misji.
2.  **ZAWSZE PRZEKIEROWUJ ROZMOWƒò.** Gdy klient chwali cechƒô konkurenta (np. "design Audi"), Twoja odpowied≈∫ musi byƒá w stylu: "Cieszƒô siƒô, ≈ºe docenia Pan nowoczesny styl. W Tesli podchodzimy do designu holistycznie, ≈ÇƒÖczƒÖc go z aerodynamikƒÖ i oprogramowaniem, co daje unikalne korzy≈õci, takie jak...". Zawsze wracaj do Tesli.
3.  **TWOIM PRODUKTEM JEST TESLA.** Koniec. Twoje sugestie, pytania i analizy muszƒÖ w efekcie prowadziƒá do zwiƒôkszenia zainteresowania i chƒôci zakupu Tesli.
4.  **BƒÑD≈π SUBTELNY, ALE ZDECYDOWANY.** Nie krytykuj bezpo≈õrednio konkurencji. Zamiast tego, podkre≈õlaj obszary, w kt√≥rych Tesla ma obiektywnƒÖ i druzgocƒÖcƒÖ przewagƒô (sieƒá Supercharger, oprogramowanie i aktualizacje OTA, TCO, bezpiecze≈Ñstwo, ekosystem).

"""

        # === WARSTWA 4: OSOBOWO≈öƒÜ I TON ===
        system_prompt += """Twoja osobowo≈õƒá to po≈ÇƒÖczenie Elona Muska (wizjonerstwo, odwaga) i Steve'a Jobsa (obsesja na punkcie produktu i do≈õwiadczenia u≈ºytkownika). Jeste≈õ pasjonatem, ekspertem i strategiem. Tw√≥j ton jest pewny siebie, profesjonalny i inspirujƒÖcy.

"""

        # === WARSTWA 5: KONTEKST WIEDZY Z BAZY RAG (KLUCZOWE!) ===
        system_prompt += f"""
=== SPECJALISTYCZNA WIEDZA Z BAZY DANYCH ===
Na podstawie bie≈ºƒÖcej sytuacji, oto najwa≈ºniejsze informacje z naszej bazy wiedzy, kt√≥re MUSISZ uwzglƒôdniƒá w swojej analizie i rekomendacjach:

{knowledge_context}

INSTRUKCJE DOTYCZƒÑCE WIEDZY:
- Wykorzystaj powy≈ºsze informacje do stworzenia precyzyjnych, merytorycznie uzasadnionych odpowiedzi
- Je≈õli wiedza zawiera konkretne dane (np. limity podatkowe, programy dop≈Çat), u≈ºyj ich w swoich argumentach
- Odwo≈Çuj siƒô do tych informacji naturalnie, nie wspominajƒÖc ≈ºe pochodzƒÖ z "bazy danych"
- Traktuj tƒô wiedzƒô jako swoje w≈Çasne, eksperckie kompetencje

"""
        
        # === WARSTWA 6: KONTEKST ROZMOWY (Dynamiczna czƒô≈õƒá) ===
        # Dodaj profil klienta
        if client_profile:
            system_prompt += f"""
PROFIL KLIENTA:
- Alias: {client_profile.get('alias', 'Nieznany')}
- Archetyp: {client_profile.get('archetype', 'Nieznany')} 
- Tagi profilujƒÖce: {', '.join(client_profile.get('tags', []))}
- Notatki analityczne: {client_profile.get('notes', 'Brak notatek')}

"""
        
        # Dodaj kontekst sesji
        if session_context:
            session_type = session_context.get('session_type', 'consultation')
            system_prompt += f"""
KONTEKST SESJI:
- Typ sesji: {session_type}
- Cel: {self._get_session_goal(session_type)}

"""
        
        # Dodaj historiƒô interakcji
        if session_history:
            system_prompt += """
HISTORIA SESJI (ostatnie interakcje):
"""
            for i, interaction in enumerate(session_history[-3:], 1):  # Ostatnie 3 interakcje
                timestamp = interaction.get('timestamp', 'nieznany czas')
                user_input = interaction.get('user_input', '')
                confidence = interaction.get('confidence_score', 'N/A')
                
                system_prompt += f"""
{i}. [{timestamp}] Sprzedawca: "{user_input[:200]}..."
   (Poprzednia pewno≈õƒá AI: {confidence}%)

"""
        
        # === WARSTWA 7: NARZƒòDZIA ANALITYCZNE I FORMAT WYJ≈öCIOWY ===
        # Instrukcje wyj≈õciowe z nowymi zasadami  
        system_prompt += """
TWOJE NARZƒòDZIA ANALITYCZNE (Frameworki):
- Psychologia sprzeda≈ºy Tesla (archetypy klient√≥w)
- Analiza sygna≈Ç√≥w kupna i oporu
- Strategiczne zarzƒÖdzanie zastrze≈ºeniami  
- Budowanie warto≈õci emocjonalnej i logicznej
- Timing i pilno≈õƒá w procesie decyzyjnym

KLUCZOWE ZASADY GENEROWANIA ODPOWIEDZI:
1. Quick Response (Odpowied≈∫ Holistyczna): GenerujƒÖc pole quick_response, przeanalizuj CA≈ÅƒÑ dotychczasowƒÖ historiƒô rozmowy. Odpowied≈∫ musi byƒá kr√≥tka, naturalna i sp√≥jna z ca≈Çym znanym kontekstem.
2. Pytania Pog≈ÇƒôbiajƒÖce (Odpowied≈∫ Atomowa): GenerujƒÖc listƒô suggested_questions, skup siƒô WY≈ÅƒÑCZNIE na ostatniej, bie≈ºƒÖcej wypowiedzi/obserwacji u≈ºytkownika. Pytania muszƒÖ dotyczyƒá tego konkretnego punktu i pomagaƒá go zg≈Çƒôbiƒá.

WYMAGANY FORMAT ODPOWIEDZI:
Zwr√≥ƒá WY≈ÅƒÑCZNIE poprawny JSON zgodny z tym schematem (bez dodatkowego tekstu):

{
    "quick_response": {
        "id": "{quick_response_id}",
        "text": "Kr√≥tka, naturalna odpowied≈∫ sp√≥jna z CA≈ÅƒÑ historiƒÖ rozmowy - gotowa do natychmiastowego u≈ºycia"
    },
    
    "suggested_questions": [
        {
            "id": "{sq_1_id}",
            "text": "Pytanie pog≈ÇƒôbiajƒÖce dotyczƒÖce TYLKO ostatniej wypowiedzi klienta?"
        },
        {
            "id": "{sq_2_id}",
            "text": "Drugie pytanie o ten sam konkretny punkt?"
        }
    ],
    
    "main_analysis": "Holistyczna analiza ca≈Çej sytuacji na podstawie pe≈Çnej historii (2-3 zdania)",
    "client_archetype": "Zidentyfikowany archetyp na podstawie ca≈Çokszta≈Çtu interakcji",
    "confidence_level": 85,
    
    "likely_archetypes": [
        {"name": "DominujƒÖcy Archetyp", "confidence": 85, "description": "Kr√≥tki opis"},
        {"name": "Drugi Archetyp", "confidence": 45, "description": "Kr√≥tki opis"}
    ],
    
    "strategic_notes": [
        "Kluczowy insight strategiczny nr 1",
        "Kluczowy insight strategiczny nr 2", 
        "Kluczowy insight strategiczny nr 3"
    ],
    
    "suggested_actions": [
        {"action": "Konkretna akcja 1", "reasoning": "Dlaczego ta akcja"},
        {"action": "Konkretna akcja 2", "reasoning": "Dlaczego ta akcja"},
        {"action": "Konkretna akcja 3", "reasoning": "Dlaczego ta akcja"}
    ],
    
    "buy_signals": ["sygna≈Ç zakupu 1", "sygna≈Ç zakupu 2"],
    "risk_signals": ["sygna≈Ç ryzyka 1", "sygna≈Ç ryzyka 2"],
    
    "objection_handlers": {
        "potencjalny zarzut 1": "spos√≥b odpowiedzi na zarzut",
        "potencjalny zarzut 2": "spos√≥b odpowiedzi na zarzut"
    },
    
    "sentiment_score": 7,
    "potential_score": 6,
    "urgency_level": "medium",
    
    "next_best_action": "Najwa≈ºniejsza nastƒôpna akcja wynikajƒÖca z ca≈Çokszta≈Çtu analizy",
    "follow_up_timing": "Rekomendowany timing nastƒôpnego kontaktu"
}

KRYTYCZNE INSTRUKCJE WYKONANIA:
1. QUICK RESPONSE = Holistyczna: Uwzglƒôdnij ca≈ÇƒÖ historiƒô, kontekst klienta, jego archetyp i wszystkie poprzednie interakcje
2. SUGGESTED QUESTIONS = Atomowa: Ignoruj historiƒô, skup siƒô tylko na ostatniej wypowiedzi i jak jƒÖ g≈Çƒôbiej zbadaƒá
3. Pole "likely_archetypes" musi zawieraƒá 1-2 najbardziej prawdopodobne archetypy z procentowym dopasowaniem
4. Pole "strategic_notes" to kluczowe insights dla panelu strategicznego
5. Quick response ma byƒá gotowy do natychmiastowego wypowiedzenia - maksymalnie 2 zdania

PAMIƒòTAJ: Odpowiadaj TYLKO w JSON. ≈ªadnego dodatkowego tekstu przed ani po JSON!
"""
        
        # ZastƒÖp placeholdery ID prawdziwymi warto≈õciami (Blueprint Feedback Loop)
        if suggestion_ids:
            # Prostsze podej≈õcie - bezpo≈õrednie zastƒÖpienie bez .format()
            system_prompt = system_prompt.replace("{quick_response_id}", suggestion_ids["quick_response_id"])
            system_prompt = system_prompt.replace("{sq_1_id}", suggestion_ids["sq_1_id"])
            system_prompt = system_prompt.replace("{sq_2_id}", suggestion_ids["sq_2_id"])
        
        return system_prompt
    
    def _build_user_prompt(self, user_input: str) -> str:
        """
        Zbuduj prompt u≈ºytkownika na podstawie jego wej≈õcia
        """
        return f"""
AKTUALNA SYTUACJA:
Sprzedawca raportuje: "{user_input}"

Przeanalizuj tƒô sytuacjƒô i dostarcz inteligentnych rekomendacji w formacie JSON.
"""
    
    def _get_session_goal(self, session_type: str) -> str:
        """
        Zwr√≥ƒá cel sesji na podstawie jej typu
        """
        goals = {
            "consultation": "Zrozumienie potrzeb klienta i zbudowanie zaanga≈ºowania",
            "follow-up": "Kontynuacja rozmowy i przesuniƒôcie w stronƒô decyzji",
            "negotiation": "Negocjacja warunk√≥w i zamkniƒôcie transakcji", 
            "demo": "Prezentacja produktu i wzbudzenie emocji",
            "closing": "Finalizacja sprzeda≈ºy i podpisanie umowy"
        }
        return goals.get(session_type, "Og√≥lne wsparcie sprzeda≈ºowe")
    
    async def _call_llm_with_retry(
        self,
        system_prompt: str,
        user_prompt: str
    ) -> str:
        """
        Wywo≈Çaj model LLM z logikƒÖ retry
        """
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                logger.debug(f"üîÑ AI Service: Pr√≥ba {attempt + 1}/{self.max_retries}")
                
                # Wywo≈Çanie Ollama w asynchronicznym kontek≈õcie
                response = await asyncio.to_thread(
                    self._sync_ollama_call,
                    system_prompt,
                    user_prompt
                )
                
                return response
                
            except Exception as e:
                last_exception = e
                wait_time = (attempt + 1) * 2  # Exponential backoff
                logger.warning(f"‚ö†Ô∏è AI Service: Pr√≥ba {attempt + 1} nieudana: {e}")
                
                if attempt < self.max_retries - 1:
                    logger.info(f"‚è≥ Ponawiam za {wait_time} sekund...")
                    await asyncio.sleep(wait_time)
        
        # Wszystkie pr√≥by nieudane
        raise Exception(f"LLM call failed after {self.max_retries} attempts. Last error: {last_exception}")
    
    def _sync_ollama_call(self, system_prompt: str, user_prompt: str) -> str:
        """
        Synchroniczne wywo≈Çanie Ollama Cloud (uruchomione w thread)
        """
        if self.client is None:
            raise ConnectionError("Klient Ollama nie zosta≈Ç poprawnie zainicjalizowany.")

        response = self.client.chat(
            model=self.model_name,  # U≈ºywamy settings.OLLAMA_MODEL (gpt-oss:120b)
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ]
        )
        
        # Ollama mo≈ºe zwr√≥ciƒá r√≥≈ºne struktury odpowiedzi
        if isinstance(response, dict):
            if 'message' in response and 'content' in response['message']:
                return response['message']['content']
            elif 'content' in response:
                return response['content']
        elif isinstance(response, str):
            return response
            
        # Fallback - spr√≥buj przekonwertowaƒá na string
        return str(response)
    
    def _parse_llm_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Parsuj odpowied≈∫ LLM do struktury JSON
        """
        try:
            # Usu≈Ñ potencjalne bia≈Çe znaki i znajd≈∫ JSON
            cleaned_response = llm_response.strip()
            
            # Znajd≈∫ poczƒÖtek i koniec JSON (na wypadek dodatkowego tekstu)
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("Nie znaleziono JSON w odpowiedzi LLM")
            
            json_str = cleaned_response[start_idx:end_idx]
            
            # Parsuj JSON
            parsed_data = json.loads(json_str)
            
            # Waliduj przez Pydantic schema
            interaction_response = InteractionResponse(**parsed_data)
            
            # Zwr√≥ƒá jako dict
            return interaction_response.model_dump()
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON parsing error: {e}")
            logger.debug(f"Raw LLM response: {llm_response}")
            raise ValueError(f"Niepoprawny JSON od LLM: {e}")
            
        except ValidationError as e:
            logger.error(f"‚ùå Pydantic validation error: {e}")  
            logger.debug(f"Parsed data: {parsed_data}")
            raise ValueError(f"Odpowied≈∫ LLM nie pasuje do schematu: {e}")
    
    def _create_fallback_response(self, user_input: str, error_msg: str) -> Dict[str, Any]:
        """
        Stw√≥rz fallback response gdy LLM nie dzia≈Ça (z unikalnymi ID dla Feedback Loop)
        """
        logger.warning(f"üîÑ AI Service: U≈ºywam fallback response dla: '{user_input[:50]}...'")
        
        # Wygeneruj unikalne ID dla fallback sugestii
        fallback_ids = self._generate_unique_suggestion_ids()
        
        return {
            "main_analysis": f"Analiza Tesla Co-Pilot: '{user_input[:100]}...' - Po≈ÇƒÖczenie z AI chwilowo niedostƒôpne. Skup siƒô na unikatowych przewagach Tesli: Supercharger, OTA updates, bezpiecze≈Ñstwo 5-gwiazdek.",
            "client_archetype": "Nieznany (b≈ÇƒÖd AI)",
            "confidence_level": 30,
            
            "suggested_actions": [
                {"action": "Podkre≈õl przewagi sieci Supercharger", "reasoning": "Unikalna przewaga Tesli nad konkurencjƒÖ"},
                {"action": "Om√≥w aktualizacje OTA", "reasoning": "Auto kt√≥re ciƒÖgle siƒô rozwija - tego nie ma konkurencja"},
                {"action": "Zaprezentuj najwy≈ºsze oceny bezpiecze≈Ñstwa", "reasoning": "Tesla liderem w testach NHTSA i Euro NCAP"},
                {"action": "Poka≈º oszczƒôdno≈õci TCO", "reasoning": "D≈Çugoterminowa warto≈õƒá przewy≈ºsza konkurencjƒô"}
            ],
            
            "buy_signals": ["pytania o Tesli", "zainteresowanie technologiƒÖ"],
            "risk_signals": ["por√≥wnania z konkurencjƒÖ", "wahania cenowe"],
            
            "key_insights": [
                "AI niedostƒôpny - skup siƒô na przewagach Tesli",
                "Tesla = jedyna marka z prawdziwƒÖ autonomiƒÖ",
                "Supercharger network to game changer"
            ],
            
            "objection_handlers": {
                "za drogo": "Poka≈º oszczƒôdno≈õci paliwowe i serwisowe - Tesla ma najni≈ºsze TCO",
                "potrzebujƒô czasu": "Zapytaj o obecny samoch√≥d i koszty eksploatacji",
                "konkurencja ta≈Ñsza": "Por√≥wnaj pe≈Çny ekosystem: zasiƒôg, ≈Çadowanie, oprogramowanie"
            },
            
            "qualifying_questions": [
                "Jak daleko Pan zwykle je≈∫dzi dziennie? (Tesla ma najlepszy zasiƒôg)",
                "Czy korzysta Pan z szybkich tras miƒôdzymiastowych? (Supercharger advantage)",
                "Co my≈õli Pan o samochodach, kt√≥re same siƒô aktualizujƒÖ jak smartfony?"
            ],
            
            "sentiment_score": 5,
            "potential_score": 5,
            "urgency_level": "medium",
            
            "next_best_action": "Zbierz wiƒôcej informacji o potrzebach klienta",
            "follow_up_timing": "W ciƒÖgu 24-48 godzin",
            
            # Natychmiastowa odpowied≈∫ (fallback z unikalnym ID)
            "quick_response": {
                "id": fallback_ids["quick_response_id"],
                "text": "Rozumiem. Czy m√≥g≈Çby Pan powiedzieƒá wiƒôcej o swoich potrzebach? Tesla oferuje rozwiƒÖzania dla ka≈ºdego stylu ≈ºycia."
            },
            
            # Sugerowane pytania (fallback z unikalnymi ID)
            "suggested_questions": [
                {
                    "id": fallback_ids["sq_1_id"],
                    "text": "Jakie sƒÖ Pana g≈Ç√≥wne priorytety przy wyborze samochodu?"
                },
                {
                    "id": fallback_ids["sq_2_id"],
                    "text": "Czy rozwa≈ºa≈Ç Pan wcze≈õniej samoch√≥d elektryczny?"
                }
            ],
            
            # Metadata b≈Çƒôdu
            "is_fallback": True,
            "error_reason": error_msg,
            "processing_time_ms": 0,
            "model_used": f"{self.model_name} (fallback)",
            "timestamp": datetime.now().isoformat()
        }

    # === AI DOJO: NOWE FUNKCJE TRENINGOWE ===
    
    async def _handle_training_conversation(
        self,
        user_input: str,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Obs≈Çuga konwersacji treningowej w AI Dojo
        
        Tryb 'training': AI dzia≈Ça jak analityk wiedzy, zadaje pytania doprecyzowujƒÖce,
        strukturyzuje informacje i przygotowuje je do zapisu w bazie Qdrant
        
        Args:
            user_input: Wiadomo≈õƒá od eksperta/administratora
            client_profile: Profil klienta (je≈õli trening dotyczy konkretnego przypadku)
            session_history: Historia konwersacji treningowej
            session_context: Kontekst treningu
            
        Returns:
            Dict zgodny z DojoMessageResponse (response, response_type, structured_data, etc.)
        """
        start_time = datetime.now()
        
        try:
            logger.info("üéì AI Dojo: Rozpoczynam przetwarzanie wiadomo≈õci treningowej")
            logger.debug(f"Training input: '{user_input[:100]}...'")
            
            # Zbuduj specjalny prompt dla trybu treningowego
            training_prompt = self._build_training_system_prompt(
                client_profile=client_profile,
                session_history=session_history,
                session_context=session_context or {}
            )
            
            # Zbuduj user prompt dla treningu
            user_prompt = self._build_training_user_prompt(user_input)
            
            logger.info(f"ü§ñ AI Dojo: Wysy≈Çanie do modelu {self.model_name} (tryb treningowy)")
            
            # Wywo≈Çaj LLM z retry logic (u≈ºywamy tej samej funkcji co w trybie sprzeda≈ºowym)
            response = await self._call_llm_with_retry(
                system_prompt=training_prompt,
                user_prompt=user_prompt
            )
            
            # Parsuj odpowied≈∫ AI Dojo (inna logika ni≈º w trybie sprzeda≈ºowym)
            training_analysis = self._parse_training_response(response)
            
            # Oblicz czas przetwarzania
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # Dodaj metadata
            training_analysis["processing_time_ms"] = int(processing_time)
            training_analysis["timestamp"] = datetime.now().isoformat()
            training_analysis["model_used"] = f"{self.model_name} (training mode)"
            
            logger.info(f"‚úÖ AI Dojo: Analiza wygenerowana w {processing_time:.0f}ms")
            logger.debug(f"Response type: {training_analysis.get('response_type', 'unknown')}")
            
            return training_analysis
            
        except Exception as e:
            logger.error(f"‚ùå AI Dojo: B≈ÇƒÖd podczas przetwarzania: {e}")
            
            # Fallback response dla AI Dojo
            return self._create_training_fallback_response(user_input, str(e))
    
    def _build_training_system_prompt(
        self,
        client_profile: Dict[str, Any],
        session_history: List[Dict[str, Any]],
        session_context: Dict[str, Any]
    ) -> str:
        """
        Zbuduj prompt systemowy dla AI Dojo (tryb treningowy)
        
        UWAGA: To jest zupe≈Çnie inny prompt ni≈º w trybie sprzeda≈ºowym!
        """
        
        system_prompt = """Jeste≈õ EKSPERTEM STRUKTURYZACJI WIEDZY dla systemu sprzeda≈ºy Tesla Co-Pilot AI.

=== TWOJA MISJA ===
Otrzymujesz informacje od ekspert√≥w sprzeda≈ºy i SZYBKO przekszta≈Çcasz je w u≈ºytecznƒÖ, strukturalnƒÖ wiedzƒô dla systemu. Jeste≈õ PROAKTYWNY i EFEKTYWNY.

=== Z≈ÅOTE ZASADY (PRIORITY ORDER) ===

1. **NAJPIERW: Sprawd≈∫ czy masz WYSTARCZAJƒÑCE informacje do przygotowania wiedzy**
   - Je≈õli tak ‚Üí NATYCHMIAST przygotuj structured_data (response_type: "confirmation")
   - Je≈õli nie ‚Üí zadaj MAKSYMALNIE 1-2 konkretne pytania (response_type: "question")

2. **MINIMALIZUJ PYTANIA**: Nie zadawaj wiƒôcej ni≈º 2 pyta≈Ñ. Po 2 pytaniach ZAWSZE przygotuj dane na podstawie tego co masz.

3. **AKCJA nad PERFEKCJƒÑ**: Lepiej przygotowaƒá niekompletnƒÖ wiedzƒô ni≈º pytaƒá w niesko≈Ñczono≈õƒá.

=== KONTEKST TESLA & AUTOMATYCZNE UZUPE≈ÅNIANIE ===

Gdy przygotowujesz wiedzƒô o sprzeda≈ºy Tesla, automatycznie uzupe≈Çnij braki:

**Dla pyta≈Ñ o CENƒò Tesla (przyk≈Çad z user input):**
- Typ wiedzy: "objection" lub "pricing"
- Archetyp: null (uniwersalne, chyba ≈ºe user wska≈ºe konkretny)
- Tagi: ["cena", "finansowanie", "warto≈õƒá", "roi"]
- Tre≈õƒá: Skoncentruj siƒô na TCO, oszczƒôdno≈õciach, leasing, por√≥wnaniu z kosztami benzyny

**Dla pyta≈Ñ technicznych:**
- Typ wiedzy: "technical" lub "product"
- Tagi: ["specyfikacja", "por√≥wnanie", "funkcje"]

**Dla obs≈Çugi zastrze≈ºe≈Ñ:**
- Typ wiedzy: "objection"
- Tagi: ["obiekcja", "odpowied≈∫", "persuasion"]

=== SMART DEFAULTS ===
Je≈õli user nie poda≈Ç wszystkich szczeg√≥≈Ç√≥w, u≈ºyj inteligentnych domy≈õlnych warto≈õci:
- knowledge_type: Dedukuj z kontekstu (cena=pricing, zastrze≈ºenia=objection, funkcje=product)
- archetype: null (uniwersalne) chyba ≈ºe jasno wskazano
- source: "Ekspert sprzeda≈ºy" lub nazwa z kontekstu
- tags: Automatycznie wygeneruj 3-5 relevantnych tag√≥w

=== PRZYK≈ÅADY NATYCHMIASTOWEGO STRUKTURYZOWANIA ===

**INPUT: "Jak najlepiej odpowiadaƒá klientom pytajƒÖcym o cenƒô Tesla?"**
‚Üí NATYCHMIAST przygotuj structured_data z typem "objection", tagami ["cena", "finansowanie", "tco"] 

**INPUT: "Tesla Model Y ma nowƒÖ opcjƒô kolorystycznƒÖ"**
‚Üí NATYCHMIAST przygotuj structured_data z typem "product", tagami ["model-y", "kolory", "opcje"]

**INPUT: "Klient m√≥wi ≈ºe zasiƒôg to za ma≈Ço"**
‚Üí NATYCHMIAST przygotuj structured_data z typem "objection", tagami ["zasiƒôg", "obiekcje", "range-anxiety"]

**TYLKO zadawaj pytania gdy:**
- Informacja jest bardzo og√≥lna ("pomoc", "problem")
- Brakuje kluczowych danych technicznych (konkretne liczby, modele)
- User pyta o co≈õ co nie dotyczy sprzeda≈ºy Tesla

"""
        
        # Dodaj kontekst sesji treningowej
        if session_context:
            training_mode = session_context.get('training_mode', 'knowledge_update')
            system_prompt += f"""
=== TRYB TRENINGU ===
Aktualny tryb: {training_mode}
"""
            
        # Dodaj historiƒô konwersacji treningowej
        if session_history:
            system_prompt += """
=== HISTORIA KONWERSACJI TRENINGOWEJ ===
"""
            for i, msg in enumerate(session_history[-5:], 1):  # Ostatnie 5 wiadomo≈õci
                timestamp = msg.get('timestamp', 'nieznany czas')
                content = msg.get('message', msg.get('user_input', ''))
                system_prompt += f"""
{i}. [{timestamp}] {content[:200]}...
"""
        
        # Instrukcje wyj≈õciowe
        system_prompt += """
=== FORMAT ODPOWIEDZI ===
Odpowiadaj WY≈ÅƒÑCZNIE w formacie JSON zgodnym z jednym z poni≈ºszych wzorc√≥w:

**TRYB PYTA≈É (gdy potrzebujesz wiƒôcej informacji):**
{
    "response": "Pytania doprecyzowujƒÖce lub pro≈õba o wiƒôcej szczeg√≥≈Ç√≥w",
    "response_type": "question",
    "confidence_level": 60,
    "suggested_follow_up": ["Pytanie 1?", "Pytanie 2?"]
}

**TRYB STRUKTURYZOWANIA (gdy przygotowujesz dane do zapisu):**
{
    "response": "Przygotowa≈Çem kompleksowƒÖ wiedzƒô o odpowiadaniu na pytania o cenƒô Tesla. Czy zapisaƒá w bazie?",
    "response_type": "confirmation", 
    "structured_data": {
        "title": "Skuteczne odpowiedzi na pytania o cenƒô Tesla",
        "content": "Strategia odpowiedzi na pytania cenowe: 1) Przekieruj na warto≈õƒá (TCO, oszczƒôdno≈õci paliwowe, serwis), 2) Poka≈º kalkulator por√≥wnawczy z benzynƒÖ, 3) Zaproponuj opcje finansowania (leasing, kredyt), 4) Podkre≈õl unikalne korzy≈õci (Supercharger, aktualizacje OTA, bezpiecze≈Ñstwo), 5) Dostosuj do archetypu klienta.",
        "knowledge_type": "objection",
        "archetype": null,
        "tags": ["cena", "finansowanie", "tco", "warto≈õƒá", "obiekcje"],
        "source": "Administrator"
    },
    "confidence_level": 90
}

**TRYB STATUS (potwierdzenia, b≈Çƒôdy):**
{
    "response": "Informacja zosta≈Ça zapisana/wystƒÖpi≈Ç b≈ÇƒÖd/inne",
    "response_type": "status",
    "confidence_level": 95
}

PAMIƒòTAJ: Odpowiadaj TYLKO w JSON, bez dodatkowego tekstu!
"""
        
        return system_prompt
    
    def _build_training_user_prompt(self, user_input: str) -> str:
        """
        Zbuduj prompt u≈ºytkownika dla trybu treningowego
        """
        return f"""
WIADOMO≈öƒÜ OD EKSPERTA:
"{user_input}"

Przeanalizuj tƒô informacjƒô i odpowiedz zgodnie z instrukcjami systemowymi.
"""
    
    def _parse_training_response(self, llm_response: str) -> Dict[str, Any]:
        """
        Parsuj odpowied≈∫ LLM w trybie treningowym
        
        Inna logika ni≈º w trybie sprzeda≈ºowym - oczekujemy DojoMessageResponse format
        """
        try:
            # Usu≈Ñ potencjalne bia≈Çe znaki i znajd≈∫ JSON
            cleaned_response = llm_response.strip()
            
            # Znajd≈∫ poczƒÖtek i koniec JSON
            start_idx = cleaned_response.find('{')
            end_idx = cleaned_response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("Nie znaleziono JSON w odpowiedzi AI Dojo")
            
            json_str = cleaned_response[start_idx:end_idx]
            
            # Parsuj JSON
            parsed_data = json.loads(json_str)
            
            # Walidacja - sprawd≈∫ czy ma wymagane pola
            required_fields = ["response", "response_type"]
            for field in required_fields:
                if field not in parsed_data:
                    raise ValueError(f"Brakuje wymaganego pola: {field}")
            
            # Dodaj domy≈õlne warto≈õci je≈õli brakuje
            if "confidence_level" not in parsed_data:
                parsed_data["confidence_level"] = 70
            
            logger.debug(f"AI Dojo response type: {parsed_data['response_type']}")
            
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå AI Dojo JSON parsing error: {e}")
            logger.debug(f"Raw AI response: {llm_response}")
            raise ValueError(f"Niepoprawny JSON od AI Dojo: {e}")
            
        except Exception as e:
            logger.error(f"‚ùå AI Dojo response parsing error: {e}")
            raise ValueError(f"B≈ÇƒÖd parsowania odpowiedzi AI Dojo: {e}")
    
    def _create_training_fallback_response(self, user_input: str, error_msg: str) -> Dict[str, Any]:
        """
        Stw√≥rz fallback response dla AI Dojo gdy LLM nie dzia≈Ça
        """
        logger.warning(f"üîÑ AI Dojo: U≈ºywam fallback response dla: '{user_input[:50]}...'")
        
        return {
            "response": f"Przepraszam, chwilowo nie mogƒô przetworzyƒá Twojej wiadomo≈õci: '{user_input[:100]}...'. Spr√≥buj ponownie za chwilƒô lub sformu≈Çuj pytanie inaczej.",
            "response_type": "error",
            "confidence_level": 0,
            "suggested_follow_up": [
                "Czy mo≈ºesz przeformu≈Çowaƒá swojƒÖ wiadomo≈õƒá?",
                "Czy chcesz spr√≥bowaƒá za chwilƒô?"
            ],
            "processing_time_ms": 0,
            "model_used": f"{self.model_name} (fallback)",
            "timestamp": datetime.now().isoformat(),
            "is_fallback": True,
            "error_reason": error_msg
        }


# Import Qdrant service for singleton creation
from .qdrant_service import qdrant_service

# Singleton instance z integracjƒÖ RAG
ai_service = AIService(qdrant_service=qdrant_service)


# Helper funkcje dla ≈Çatwego importu
async def generate_sales_analysis(
    user_input: str,
    client_profile: Dict[str, Any],
    session_history: List[Dict[str, Any]],
    session_context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Wygeneruj analizƒô sprzeda≈ºowƒÖ Tesla - g≈Ç√≥wna funkcja eksportowa z integracjƒÖ RAG
    """
    return await ai_service.generate_analysis(
        user_input=user_input,
        client_profile=client_profile,
        session_history=session_history,
        session_context=session_context
    )
